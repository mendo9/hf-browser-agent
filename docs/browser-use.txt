Directory structure:
‚îî‚îÄ‚îÄ browser-use-browser-use/
    ‚îú‚îÄ‚îÄ README.md
    ‚îú‚îÄ‚îÄ SECURITY.md
    ‚îú‚îÄ‚îÄ docs/
    ‚îÇ   ‚îú‚îÄ‚îÄ README.md
    ‚îÇ   ‚îú‚îÄ‚îÄ development.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ introduction.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ mint.json
    ‚îÇ   ‚îú‚îÄ‚îÄ quickstart.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ cloud/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ implementation.mdx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ quickstart.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ customize/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ agent-settings.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ browser-settings.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ custom-functions.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ output-format.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ real-browser.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ sensitive-data.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ supported-models.mdx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ system-prompt.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ development/
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ contribution-guide.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ local-setup.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ observability.mdx
    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ roadmap.mdx
    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ telemetry.mdx
    ‚îÇ   ‚îú‚îÄ‚îÄ images/
    ‚îÇ   ‚îî‚îÄ‚îÄ logo/
    ‚îî‚îÄ‚îÄ examples/
        ‚îú‚îÄ‚îÄ simple.py
        ‚îú‚îÄ‚îÄ browser/
        ‚îÇ   ‚îú‚îÄ‚îÄ real_browser.py
        ‚îÇ   ‚îî‚îÄ‚îÄ using_cdp.py
        ‚îú‚îÄ‚îÄ custom-functions/
        ‚îÇ   ‚îú‚îÄ‚îÄ advanced_search.py
        ‚îÇ   ‚îú‚îÄ‚îÄ clipboard.py
        ‚îÇ   ‚îú‚îÄ‚îÄ file_upload.py
        ‚îÇ   ‚îú‚îÄ‚îÄ notification.py
        ‚îÇ   ‚îî‚îÄ‚îÄ save_to_file_hugging_face.py
        ‚îú‚îÄ‚îÄ features/
        ‚îÇ   ‚îú‚îÄ‚îÄ custom_output.py
        ‚îÇ   ‚îú‚îÄ‚îÄ custom_system_prompt.py
        ‚îÇ   ‚îú‚îÄ‚îÄ custom_user_agent.py
        ‚îÇ   ‚îú‚îÄ‚îÄ download_file.py
        ‚îÇ   ‚îú‚îÄ‚îÄ follow_up_tasks.py
        ‚îÇ   ‚îú‚îÄ‚îÄ initial_actions.py
        ‚îÇ   ‚îú‚îÄ‚îÄ multi-tab_handling.py
        ‚îÇ   ‚îú‚îÄ‚îÄ multiple_agents_same_browser.py
        ‚îÇ   ‚îú‚îÄ‚îÄ outsource_state.py
        ‚îÇ   ‚îú‚îÄ‚îÄ parallel_agents.py
        ‚îÇ   ‚îú‚îÄ‚îÄ pause_agent.py
        ‚îÇ   ‚îú‚îÄ‚îÄ planner.py
        ‚îÇ   ‚îú‚îÄ‚îÄ restrict_urls.py
        ‚îÇ   ‚îú‚îÄ‚îÄ result_processing.py
        ‚îÇ   ‚îú‚îÄ‚îÄ save_trace.py
        ‚îÇ   ‚îú‚îÄ‚îÄ sensitive_data.py
        ‚îÇ   ‚îú‚îÄ‚îÄ small_model_for_extraction.py
        ‚îÇ   ‚îî‚îÄ‚îÄ validate_output.py
        ‚îú‚îÄ‚îÄ integrations/
        ‚îÇ   ‚îú‚îÄ‚îÄ discord/
        ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ discord_api.py
        ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ discord_example.py
        ‚îÇ   ‚îî‚îÄ‚îÄ slack/
        ‚îÇ       ‚îú‚îÄ‚îÄ README.md
        ‚îÇ       ‚îú‚îÄ‚îÄ slack_api.py
        ‚îÇ       ‚îî‚îÄ‚îÄ slack_example.py
        ‚îú‚îÄ‚îÄ models/
        ‚îÇ   ‚îú‚îÄ‚îÄ README.md
        ‚îÇ   ‚îú‚îÄ‚îÄ azure_openai.py
        ‚îÇ   ‚îú‚îÄ‚îÄ bedrock_claude.py
        ‚îÇ   ‚îú‚îÄ‚îÄ claude-3.7-sonnet.py
        ‚îÇ   ‚îú‚îÄ‚îÄ deepseek-r1.py
        ‚îÇ   ‚îú‚îÄ‚îÄ deepseek.py
        ‚îÇ   ‚îú‚îÄ‚îÄ gemini.py
        ‚îÇ   ‚îú‚îÄ‚îÄ gpt-4o.py
        ‚îÇ   ‚îú‚îÄ‚îÄ ollama.py
        ‚îÇ   ‚îî‚îÄ‚îÄ qwen.py
        ‚îú‚îÄ‚îÄ notebook/
        ‚îÇ   ‚îî‚îÄ‚îÄ agent_browsing.ipynb
        ‚îú‚îÄ‚îÄ ui/
        ‚îÇ   ‚îú‚îÄ‚îÄ README.md
        ‚îÇ   ‚îú‚îÄ‚îÄ command_line.py
        ‚îÇ   ‚îú‚îÄ‚îÄ gradio_demo.py
        ‚îÇ   ‚îî‚îÄ‚îÄ streamlit_demo.py
        ‚îî‚îÄ‚îÄ use-cases/
            ‚îú‚îÄ‚îÄ README.md
            ‚îú‚îÄ‚îÄ captcha.py
            ‚îú‚îÄ‚îÄ check_appointment.py
            ‚îú‚îÄ‚îÄ find_and_apply_to_jobs.py
            ‚îú‚îÄ‚îÄ find_influencer_profiles.py
            ‚îú‚îÄ‚îÄ google_sheets.py
            ‚îú‚îÄ‚îÄ online_coding_agent.py
            ‚îú‚îÄ‚îÄ post-twitter.py
            ‚îú‚îÄ‚îÄ scrolling_page.py
            ‚îú‚îÄ‚îÄ shopping.py
            ‚îú‚îÄ‚îÄ test_cv.txt
            ‚îú‚îÄ‚îÄ twitter_cookies.txt
            ‚îú‚îÄ‚îÄ twitter_post_using_cookies.py
            ‚îú‚îÄ‚îÄ web_voyager_agent.py
            ‚îî‚îÄ‚îÄ wikipedia_banana_to_quantum.py

================================================
File: README.md
================================================
<picture>
  <source media="(prefers-color-scheme: dark)" srcset="./static/browser-use-dark.png">
  <source media="(prefers-color-scheme: light)" srcset="./static/browser-use.png">
  <img alt="Shows a black Browser Use Logo in light color mode and a white one in dark color mode." src="./static/browser-use.png"  width="full">
</picture>

<h1 align="center">Enable AI to control your browser ü§ñ</h1>

[![GitHub stars](https://img.shields.io/github/stars/gregpr07/browser-use?style=social)](https://github.com/gregpr07/browser-use/stargazers)
[![Discord](https://img.shields.io/discord/1303749220842340412?color=7289DA&label=Discord&logo=discord&logoColor=white)](https://link.browser-use.com/discord)
[![Cloud](https://img.shields.io/badge/Cloud-‚òÅÔ∏è-blue)](https://cloud.browser-use.com)
[![Documentation](https://img.shields.io/badge/Documentation-üìï-blue)](https://docs.browser-use.com)
[![Twitter Follow](https://img.shields.io/twitter/follow/Gregor?style=social)](https://x.com/gregpr07)
[![Twitter Follow](https://img.shields.io/twitter/follow/Magnus?style=social)](https://x.com/mamagnus00)
[![Weave Badge](https://img.shields.io/endpoint?url=https%3A%2F%2Fapp.workweave.ai%2Fapi%2Frepository%2Fbadge%2Forg_T5Pvn3UBswTHIsN1dWS3voPg%2F881458615&labelColor=#EC6341)](https://app.workweave.ai/reports/repository/org_T5Pvn3UBswTHIsN1dWS3voPg/881458615)

üåê Browser-use is the easiest way to connect your AI agents with the browser.

üí° See what others are building and share your projects in our [Discord](https://link.browser-use.com/discord)! Want Swag? Check out our [Merch store](https://browsermerch.com).

üå§Ô∏è Skip the setup - try our <b>hosted version</b> for instant browser automation! <b>[Try the cloud ‚òÅÔ∏é](https://cloud.browser-use.com)</b>.

# Quick start

With pip (Python>=3.11):

```bash
pip install browser-use
```

install playwright:

```bash
playwright install
```

Spin up your agent:

```python
from langchain_openai import ChatOpenAI
from browser_use import Agent
import asyncio
from dotenv import load_dotenv
load_dotenv()

async def main():
    agent = Agent(
        task="Compare the price of gpt-4o and DeepSeek-V3",
        llm=ChatOpenAI(model="gpt-4o"),
    )
    await agent.run()

asyncio.run(main())
```

Add your API keys for the provider you want to use to your `.env` file.

```bash
OPENAI_API_KEY=
```

For other settings, models, and more, check out the [documentation üìï](https://docs.browser-use.com).

### Test with UI

You can test [browser-use with a UI repository](https://github.com/browser-use/web-ui)

Or simply run the gradio example:

```
uv pip install gradio
```

```bash
python examples/ui/gradio_demo.py
```

# Demos

<br/><br/>

[Task](https://github.com/browser-use/browser-use/blob/main/examples/use-cases/shopping.py): Add grocery items to cart, and checkout.

[![AI Did My Groceries](https://github.com/user-attachments/assets/d9359085-bde6-41d4-aa4e-6520d0221872)](https://www.youtube.com/watch?v=L2Ya9PYNns8)

<br/><br/>

Prompt: Add my latest LinkedIn follower to my leads in Salesforce.

![LinkedIn to Salesforce](https://github.com/user-attachments/assets/1440affc-a552-442e-b702-d0d3b277b0ae)

<br/><br/>

[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/use-cases/find_and_apply_to_jobs.py): Read my CV & find ML jobs, save them to a file, and then start applying for them in new tabs, if you need help, ask me.'

https://github.com/user-attachments/assets/171fb4d6-0355-46f2-863e-edb04a828d04

<br/><br/>

[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/browser/real_browser.py): Write a letter in Google Docs to my Papa, thanking him for everything, and save the document as a PDF.

![Letter to Papa](https://github.com/user-attachments/assets/242ade3e-15bc-41c2-988f-cbc5415a66aa)

<br/><br/>

[Prompt](https://github.com/browser-use/browser-use/blob/main/examples/custom-functions/save_to_file_hugging_face.py): Look up models with a license of cc-by-sa-4.0 and sort by most likes on Hugging face, save top 5 to file.

https://github.com/user-attachments/assets/de73ee39-432c-4b97-b4e8-939fd7f323b3

<br/><br/>

## More examples

For more examples see the [examples](examples) folder or join the [Discord](https://link.browser-use.com/discord) and show off your project.

# Vision

Tell your computer what to do, and it gets it done.

## Roadmap

### Agent

- [ ] Improve agent memory (summarize, compress, RAG, etc.)
- [ ] Enhance planning capabilities (load website specific context)
- [ ] Reduce token consumption (system prompt, DOM state)

### DOM Extraction

- [ ] Improve extraction for datepickers, dropdowns, special elements
- [ ] Improve state representation for UI elements

### Rerunning tasks

- [ ] LLM as fallback
- [ ] Make it easy to define workfows templates where LLM fills in the details
- [ ] Return playwright script from the agent

### Datasets

- [ ] Create datasets for complex tasks
- [ ] Benchmark various models against each other
- [ ] Fine-tuning models for specific tasks

### User Experience

- [ ] Human-in-the-loop execution
- [ ] Improve the generated GIF quality
- [ ] Create various demos for tutorial execution, job application, QA testing, social media, etc.

## Contributing

We love contributions! Feel free to open issues for bugs or feature requests. To contribute to the docs, check out the `/docs` folder.

## Local Setup

To learn more about the library, check out the [local setup üìï](https://docs.browser-use.com/development/local-setup).

## Cooperations

We are forming a commission to define best practices for UI/UX design for browser agents.
Together, we're exploring how software redesign improves the performance of AI agents and gives these companies a competitive advantage by designing their existing software to be at the forefront of the agent age.

Email [Toby](mailto:tbiddle@loop11.com?subject=I%20want%20to%20join%20the%20UI/UX%20commission%20for%20AI%20agents&body=Hi%20Toby%2C%0A%0AI%20found%20you%20in%20the%20browser-use%20GitHub%20README.%0A%0A) to apply for a seat on the committee.

## Swag

Want to show off your Browser-use swag? Check out our [Merch store](https://browsermerch.com). Good contributors will receive swag for free üëÄ.

## Citation

If you use Browser Use in your research or project, please cite:

```bibtex
@software{browser_use2024,
  author = {M√ºller, Magnus and ≈Ωuniƒç, Gregor},
  title = {Browser Use: Enable AI to control your browser},
  year = {2024},
  publisher = {GitHub},
  url = {https://github.com/browser-use/browser-use}
}
```

 <div align="center"> <img src="https://github.com/user-attachments/assets/06fa3078-8461-4560-b434-445510c1766f" width="400"/> 

 
[![Twitter Follow](https://img.shields.io/twitter/follow/Gregor?style=social)](https://x.com/gregpr07)
[![Twitter Follow](https://img.shields.io/twitter/follow/Magnus?style=social)](https://x.com/mamagnus00)
 
 </div>

<div align="center">
Made with ‚ù§Ô∏è in Zurich and San Francisco
 </div>



================================================
File: SECURITY.md
================================================
## Reporting Security Issues

If you believe you have found a security vulnerability in browser-use, please report it through coordinated disclosure.

**Please do not report security vulnerabilities through the repository issues, discussions, or pull requests.**

Instead, please open a new [Github security advisory](https://github.com/browser-use/browser-use/security/advisories/new).

Please include as much of the information listed below as you can to help me better understand and resolve the issue:

* The type of issue (e.g., buffer overflow, SQL injection, or cross-site scripting)
* Full paths of source file(s) related to the manifestation of the issue
* The location of the affected source code (tag/branch/commit or direct URL)
* Any special configuration required to reproduce the issue
* Step-by-step instructions to reproduce the issue
* Proof-of-concept or exploit code (if possible)
* Impact of the issue, including how an attacker might exploit the issue

This information will help me triage your report more quickly.




================================================
File: docs/README.md
================================================
# Docs

The official documentation for Browser Use. The docs are published to [Browser Use Docs](https://docs.browser-use.com).

### Development

Install the [Mintlify CLI](https://www.npmjs.com/package/mintlify) to preview the documentation changes locally. To install, use the following command

```
npm i -g mintlify
```

Run the following command at the root of your documentation (where mint.json is)

```
mintlify dev
```



================================================
File: docs/development.mdx
================================================
---
title: 'Development'
description: 'Preview changes locally to update your docs'
---

<Info>
  **Prerequisite**: Please install Node.js (version 19 or higher) before proceeding.
</Info>

Follow these steps to install and run Mintlify on your operating system:

**Step 1**: Install Mintlify:

<CodeGroup>

  ```bash npm
  npm i -g mintlify
  ```

```bash yarn
yarn global add mintlify
```

</CodeGroup>

**Step 2**: Navigate to the docs directory (where the `mint.json` file is located) and execute the following command:

```bash
mintlify dev
```

A local preview of your documentation will be available at `http://localhost:3000`.

### Custom Ports

By default, Mintlify uses port 3000. You can customize the port Mintlify runs on by using the `--port` flag. To run Mintlify on port 3333, for instance, use this command:

```bash
mintlify dev --port 3333
```

If you attempt to run Mintlify on a port that's already in use, it will use the next available port:

```md
Port 3000 is already in use. Trying 3001 instead.
```

## Mintlify Versions

Please note that each CLI release is associated with a specific version of Mintlify. If your local website doesn't align with the production version, please update the CLI:

<CodeGroup>

```bash npm
npm i -g mintlify@latest
```

```bash yarn
yarn global upgrade mintlify
```

</CodeGroup>

## Validating Links

The CLI can assist with validating reference links made in your documentation. To identify any broken links, use the following command:

```bash
mintlify broken-links
```

## Deployment

<Tip>
  Unlimited editors available under the [Pro
  Plan](https://mintlify.com/pricing) and above.
</Tip>

If the deployment is successful, you should see the following:

<Frame>
  <img src="/images/checks-passed.png" style={{ borderRadius: '0.5rem' }} />
</Frame>

## Code Formatting

We suggest using extensions on your IDE to recognize and format MDX. If you're a VSCode user, consider the [MDX VSCode extension](https://marketplace.visualstudio.com/items?itemName=unifiedjs.vscode-mdx) for syntax highlighting, and [Prettier](https://marketplace.visualstudio.com/items?itemName=esbenp.prettier-vscode) for code formatting.

## Troubleshooting

<AccordionGroup>
  <Accordion title='Error: Could not load the "sharp" module using the darwin-arm64 runtime'>

    This may be due to an outdated version of node. Try the following:
    1. Remove the currently-installed version of mintlify: `npm remove -g mintlify`
    2. Upgrade to Node v19 or higher.
    3. Reinstall mintlify: `npm install -g mintlify`
  </Accordion>

  <Accordion title="Issue: Encountering an unknown error">
  
    Solution: Go to the root of your device and delete the \~/.mintlify folder. Afterwards, run `mintlify dev` again.
  </Accordion>
</AccordionGroup>

Curious about what changed in the CLI version? [Check out the CLI changelog.](https://www.npmjs.com/package/mintlify?activeTab=versions)



================================================
File: docs/introduction.mdx
================================================
---
title: "Introduction"
description: "Welcome to Browser Use - We enable AI to control your browser"
icon: "book-open"
---

<img className="block" src="/images/browser-use.png" alt="Browser Use" />

## Overview

Browser Use is the easiest way to connect your AI agents with the browser. It makes websites accessible for AI agents by providing a powerful, yet simple interface for browser automation.

<Note>
  If you have used Browser Use for your project, feel free to show it off in our
  [Discord community](https://link.browser-use.com/discord)!
</Note>

## Getting Started

<CardGroup cols={2}>
  <Card title="Quick Start" icon="rocket" href="/quickstart">
    Get up and running with Browser Use in minutes
  </Card>
  <Card
    title="Supported Models"
    icon="robot"
    href="/customize/supported-models"
  >
    Configure different LLMs for your agents
  </Card>
  <Card title="Agent Settings" icon="gear" href="/customize/agent-settings">
    Learn how to configure and customize your agents
  </Card>
  <Card title="Custom Functions" icon="code" href="/customize/custom-functions">
    Extend functionality with custom actions
  </Card>
</CardGroup>

## Fancy Demos

### Writing in Google Docs

Task: Write a letter in Google Docs to my Papa, thanking him for everything, and save the document as a PDF.

<Frame>
  <img src="https://github.com/user-attachments/assets/242ade3e-15bc-41c2-988f-cbc5415a66aa" />
</Frame>

### Job Applications

Task: Read my CV & find ML jobs, save them to a file, and then start applying for them in new tabs.

<Frame>
  <video
    controls
    src="https://github.com/user-attachments/assets/171fb4d6-0355-46f2-863e-edb04a828d04"
  />
</Frame>

### Flight Search

Task: Find flights on kayak.com from Zurich to Beijing.

<Frame>
  <img src="https://github.com/user-attachments/assets/ea605d4a-90e6-481e-a569-f0e0db7e6390" />
</Frame>

### Data Collection

Task: Look up models with a license of cc-by-sa-4.0 and sort by most likes on Hugging Face, save top 5 to file.

<Frame>
  <video
    controls
    src="https://github.com/user-attachments/assets/de73ee39-432c-4b97-b4e8-939fd7f323b3"
  />
</Frame>

## Community & Support

<CardGroup cols={2}>
  <Card
    title="Join Discord"
    icon="discord"
    href="https://link.browser-use.com/discord"
  >
    Join our community for support and showcases
  </Card>
  <Card
    title="GitHub"
    icon="github"
    href="https://github.com/browser-use/browser-use"
  >
    Star us on GitHub and contribute to development
  </Card>
</CardGroup>

<Note>
  Browser Use is MIT licensed and actively maintained. We welcome contributions
  and feedback from the community!
</Note>



================================================
File: docs/mint.json
================================================
{
  "$schema": "https://mintlify.com/schema.json",
  "name": "Browser Use",
  "logo": {
    "dark": "/logo/dark.svg",
    "light": "/logo/light.svg",
    "href": "https://browser-use.com"
  },
  "favicon": "/favicon.svg",
  "colors": {
    "primary": "#F97316",
    "light": "#FFF7ED",
    "dark": "#C2410C",
    "anchors": {
      "from": "#F97316",
      "to": "#FB923C"
    },
    "background": {
      "dark": "#0D0A09"
    }
  },
  "feedback": {
    "thumbsRating": true,
    "raiseIssue": true,
    "suggestEdit": true
  },
  "topbarLinks": [
    {
      "name": "Github",
      "url": "https://github.com/browser-use/browser-use"
    },
    {
      "name": "Twitter",
      "url": "https://x.com/gregpr07"
    }
  ],
  "topbarCtaButton": {
    "name": "Join Discord",
    "url": "https://link.browser-use.com/discord"
  },
  "tabs": [
    {
      "name": "Cloud API",
      "url": "cloud",
      "openapi": "https://api.browser-use.com/openapi.json"
    }
  ],
  "navigation": [
    {
      "group": "Get Started",
      "pages": ["introduction", "quickstart"]
    },
    {
      "group": "Customize",
      "pages": [
        "customize/supported-models",
        "customize/agent-settings",
        "customize/browser-settings",
        "customize/real-browser",
        "customize/output-format",
        "customize/system-prompt",
        "customize/sensitive-data",
        "customize/custom-functions"
      ]
    },
    {
      "group": "Development",
      "pages": [
        "development/local-setup",
        "development/telemetry",
        "development/observability",
        "development/roadmap"
      ]
    },
    {
      "group": "Cloud API",
      "pages": ["cloud/quickstart", "cloud/implementation"]
    }
  ],
  "footerSocials": {
    "x": "https://x.com/gregpr07",
    "github": "https://github.com/browser-use/browser-use",
    "linkedin": "https://linkedin.com/company/browser-use"
  }
}



================================================
File: docs/quickstart.mdx
================================================
---
title: "Quickstart"
description: "Start using Browser Use with this quickstart guide"
icon: "rocket"
---

{/* You can install Browser Use from PyPI or clone it from Github. */}

## Prepare the environment

Browser Use requires Python 3.11 or higher.

First, we recommend using [uv](https://docs.astral.sh/uv/) to setup the Python environment.

```bash
uv venv --python 3.11
```

and activate it with:

```bash
# For Mac/Linux:
source .venv/bin/activate

# For Windows:
.venv\Scripts\activate
```

Install the dependencies:

```bash
uv pip install browser-use
```

Then install playwright:

```bash
playwright install
```

## Create an agent

Then you can use the agent as follows:

```python agent.py
from langchain_openai import ChatOpenAI
from browser_use import Agent
from dotenv import load_dotenv
load_dotenv()

import asyncio

llm = ChatOpenAI(model="gpt-4o")

async def main():
    agent = Agent(
        task="Compare the price of gpt-4o and DeepSeek-V3",
        llm=llm,
    )
    result = await agent.run()
    print(result)

asyncio.run(main())
```

## Set up your LLM API keys

`ChatOpenAI` and other Langchain chat models require API keys. You should store these in your `.env` file. For example, for OpenAI and Anthropic, you can set the API keys in your `.env` file, such as:


```bash .env
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
```

For other LLM models you can refer to the [Langchain documentation](https://python.langchain.com/docs/integrations/chat/) to find how to set them up with their specific API keys.



================================================
File: docs/cloud/implementation.mdx
================================================
---
title: "Implementing the API"
description: "Learn how to implement the Browser Use API in Python"
icon: "code"
---

This guide shows how to implement common API patterns using Python. We'll create a complete example that creates and monitors a browser automation task.

## Basic Implementation

For all settings see [Run Task](cloud/api-v10/run-task).

Here's a simple implementation using Python's `requests` library to stream the task steps:

```python
import json
import time

import requests

API_KEY = 'your_api_key_here'
BASE_URL = 'https://api.browser-use.com/api/v1'
HEADERS = {'Authorization': f'Bearer {API_KEY}'}


def create_task(instructions: str):
	"""Create a new browser automation task"""
	response = requests.post(f'{BASE_URL}/run-task', headers=HEADERS, json={'task': instructions})
	return response.json()['id']


def get_task_status(task_id: str):
	"""Get current task status"""
	response = requests.get(f'{BASE_URL}/task/{task_id}/status', headers=HEADERS)
	return response.json()


def get_task_details(task_id: str):
	"""Get full task details including output"""
	response = requests.get(f'{BASE_URL}/task/{task_id}', headers=HEADERS)
	return response.json()


def wait_for_completion(task_id: str, poll_interval: int = 2):
	"""Poll task status until completion"""
	count = 0
	unique_steps = []
	while True:
		details = get_task_details(task_id)
		new_steps = details['steps']
		# use only the new steps that are not in unique_steps.
		if new_steps != unique_steps:
			for step in new_steps:
				if step not in unique_steps:
					print(json.dumps(step, indent=4))
			unique_steps = new_steps
		count += 1
		status = details['status']

		if status in ['finished', 'failed', 'stopped']:
			return details
		time.sleep(poll_interval)


def main():
	task_id = create_task('Open https://www.google.com and search for openai')
	print(f'Task created with ID: {task_id}')
	task_details = wait_for_completion(task_id)
	print(f"Final output: {task_details['output']}")


if __name__ == '__main__':
	main()

```

## Task Control Example

Here's how to implement task control with pause/resume functionality:

```python
def control_task():
    # Create a new task
    task_id = create_task("Go to google.com and search for Browser Use")

    # Wait for 5 seconds
    time.sleep(5)

    # Pause the task
    requests.put(f"{BASE_URL}/pause-task?task_id={task_id}", headers=HEADERS)
    print("Task paused! Check the live preview.")

    # Wait for user input
    input("Press Enter to resume...")

    # Resume the task
    requests.put(f"{BASE_URL}/resume-task?task_id={task_id}", headers=HEADERS)

    # Wait for completion
    result = wait_for_completion(task_id)
    print(f"Task completed with output: {result['output']}")
```

<Note>
  Remember to handle your API key securely and implement proper error handling
  in production code.
</Note>



================================================
File: docs/cloud/quickstart.mdx
================================================
---
title: "Quickstart"
description: "Learn how to get started with the Browser Use Cloud API"
icon: "cloud"
---

The Browser Use Cloud API lets you create and manage browser automation agents programmatically. Each agent can execute tasks and provide real-time feedback through a live preview URL.

## Prerequisites

<Note>
  You need an active subscription and an API key from
  [cloud.browser-use.com/billing](https://cloud.browser-use.com/billing)
</Note>

## Pricing

The Browser Use Cloud API is priced at <b>$0.05 per step</b> that the agent executes.

<Note>
  Since Browser Use can execute multiple steps at the same time,
  the price for filling out forms is much lower than other services.
</Note>

## Creating Your First Agent

Create a new browser automation task by providing instructions in natural language:

```bash
curl -X POST https://api.browser-use.com/api/v1/run-task \
  -H "Authorization: Bearer your_api_key_here" \
  -H "Content-Type: application/json" \
  -d '{
    "task": "Go to google.com and search for Browser Use"
  }'
```

The API returns a task ID that you can use to manage the task and check the live preview URL.

<Note>
  The task response includes a `live_url` that you can embed in an iframe to
  watch and control the agent in real-time.
</Note>

## Managing Tasks

Control running tasks with these operations:

<AccordionGroup>
  <Accordion title="Pause/Resume Tasks">
    Temporarily pause task execution with [`/api/v1/pause-task`](/cloud/api-v1/pause-task) and resume with
    [`/api/v1/resume-task`](/cloud/api-v1/resume-task). Useful for manual inspection or intervention.
  </Accordion>

  <Accordion title="Stop Tasks">
    Permanently stop a task using [`/api/v1/stop-task`](/cloud/api-v1/stop-task). The task cannot be
    resumed after being stopped.
  </Accordion>
</AccordionGroup>

For detailed API documentation, see the tabs on the left, which include the full coverage of the API.

## Building your own client (OpenAPI)

<Note>
  We recommend this only if you don't need control and only need to run simple
  tasks.
</Note>

The best way to build your own client is to use our [OpenAPI specification](http://api.browser-use.com/openapi.json) to generate a type-safe client library.

### Python

Use [openapi-python-client](https://github.com/openapi-generators/openapi-python-client) to generate a modern Python client:

```bash
# Install the generator
pipx install openapi-python-client --include-deps

# Generate the client
openapi-python-client generate --url http://api.browser-use.com/openapi.json
```

This will create a Python package with full type hints, modern dataclasses, and async support.

### TypeScript/JavaScript

For TypeScript projects, use [openapi-typescript](https://www.npmjs.com/package/openapi-typescript) to generate type definitions:

```bash
# Install the generator
npm install -D openapi-typescript

# Generate the types
npx openapi-typescript http://api.browser-use.com/openapi.json -o browser-use-api.ts
```

This will create TypeScript definitions you can use with your preferred HTTP client.

<Note>
  Need help? Contact our support team at support@browser-use.com or join our
  [Discord community](https://link.browser-use.com/discord)
</Note>



================================================
File: docs/customize/agent-settings.mdx
================================================
---
title: "Agent Settings"
description: "Learn how to configure the agent"
icon: "gear"
---

## Overview

The `Agent` class is the core component of Browser Use that handles browser automation. Here are the main configuration options you can use when initializing an agent.

## Basic Settings

```python
from browser_use import Agent
from langchain_openai import ChatOpenAI

agent = Agent(
    task="Search for latest news about AI",
    llm=ChatOpenAI(model="gpt-4o"),
)
```

### Required Parameters

- `task`: The instruction for the agent to execute
- `llm`: A LangChain chat model instance. See <a href="/customize/supported-models">LangChain Models</a> for supported models.

## Agent Behavior

Control how the agent operates:

```python
agent = Agent(
    task="your task",
    llm=llm,
    controller=custom_controller,  # For custom tool calling
    use_vision=True,              # Enable vision capabilities
    save_conversation_path="logs/conversation"  # Save chat logs
)
```

### Behavior Parameters

- `controller`: Registry of functions the agent can call. Defaults to base Controller. See <a href="/customize/custom-functions">Custom Functions</a> for details.
- `use_vision`: Enable/disable vision capabilities. Defaults to `True`.
  - When enabled, the model processes visual information from web pages
  - Disable to reduce costs or use models without vision support
  - For GPT-4o, image processing costs approximately 800-1000 tokens (~$0.002 USD) per image (but this depends on the defined screen size)
- `save_conversation_path`: Path to save the complete conversation history. Useful for debugging.
- `system_prompt_class`: Custom system prompt class. See <a href="/customize/system-prompt">System Prompt</a> for customization options.

<Note>
  Vision capabilities are recommended for better web interaction understanding,
  but can be disabled to reduce costs or when using models without vision
  support.
</Note>

## (Reuse) Browser Configuration

You can configure how the agent interacts with the browser. To see more `Browser` options refer to the <a href="/customize/browser-settings">Browser Settings</a> documentation.

### Reuse Existing Browser

`browser`: A Browser Use Browser instance. When provided, the agent will reuse this browser instance and automatically create new contexts for each `run()`.

```python
from browser_use import Agent, Browser
from browser_use.browser.context import BrowserContext

# Reuse existing browser
browser = Browser()
agent = Agent(
    task=task1,
    llm=llm,
    browser=browser  # Browser instance will be reused
)

await agent.run()

# Manually close the browser
await browser.close()
```

<Note>
  Remember: in this scenario the `Browser` will not be closed automatically.
</Note>

### Reuse Existing Browser Context

`browser_context`: A Playwright browser context. Useful for maintaining persistent sessions. See <a href="/customize/persistent-browser">Persistent Browser</a> for more details.

```python
from browser_use import Agent, Browser
from playwright.async_api import BrowserContext

# Use specific browser context (preferred method)
async with await browser.new_context() as context:
    agent = Agent(
        task=task2,
        llm=llm,
        browser_context=context  # Use persistent context
    )

    # Run the agent
    await agent.run()

    # Pass the context to the next agent
    next_agent = Agent(
        task=task2,
        llm=llm,
        browser_context=context
    )

    ...

await browser.close()
```

For more information about how browser context works, refer to the [Playwright
documentation](https://playwright.dev/docs/api/class-browsercontext).

<Note>
  You can reuse the same context for multiple agents. If you do nothing, the
  browser will be automatically created and closed on `run()` completion.
</Note>

## Running the Agent

The agent is executed using the async `run()` method:

- `max_steps` (default: `100`)  
  Maximum number of steps the agent can take during execution. This prevents infinite loops and helps control execution time.

## Agent History

The method returns an `AgentHistoryList` object containing the complete execution history. This history is invaluable for debugging, analysis, and creating reproducible scripts.

```python
# Example of accessing history
history = await agent.run()

# Access (some) useful information
history.urls()              # List of visited URLs
history.screenshots()       # List of screenshot paths
history.action_names()      # Names of executed actions
history.extracted_content() # Content extracted during execution
history.errors()           # Any errors that occurred
history.model_actions()     # All actions with their parameters
```

The `AgentHistoryList` provides many helper methods to analyze the execution:

- `final_result()`: Get the final extracted content
- `is_done()`: Check if the agent completed successfully
- `has_errors()`: Check if any errors occurred
- `model_thoughts()`: Get the agent's reasoning process
- `action_results()`: Get results of all actions

<Note>
  For a complete list of helper methods and detailed history analysis
  capabilities, refer to the [AgentHistoryList source
  code](https://github.com/browser-use/browser-use/blob/main/browser_use/agent/views.py#L111).
</Note>

## Run initial actions without LLM
With [this example](https://github.com/browser-use/browser-use/blob/main/examples/features/initial_actions.py) you can run initial actions without the LLM.
Specify the action as a dictionary where the key is the action name and the value is the action parameters. You can find all our actions in the [Controller](https://github.com/browser-use/browser-use/blob/main/browser_use/controller/service.py) source code.
```python

initial_actions = [
	{'open_tab': {'url': 'https://www.google.com'}},
	{'open_tab': {'url': 'https://en.wikipedia.org/wiki/Randomness'}},
	{'scroll_down': {'amount': 1000}},
]
agent = Agent(
	task='What theories are displayed on the page?',
	initial_actions=initial_actions,
	llm=llm,
)
```

## Run with message context

You can configure the agent and provide a separate message to help the LLM understand the task better.

```python 
from langchain_openai import ChatOpenAI

agent = Agent(
    task="your task",
    message_context="Additional information about the task",
    llm = ChatOpenAI(model='gpt-4o')
)
```

## Run with planner model

You can configure the agent to use a separate planner model for high-level task planning:

```python
from langchain_openai import ChatOpenAI

# Initialize models
llm = ChatOpenAI(model='gpt-4o')
planner_llm = ChatOpenAI(model='o3-mini')

agent = Agent(
    task="your task",
    llm=llm,
    planner_llm=planner_llm,           # Separate model for planning
    use_vision_for_planner=False,      # Disable vision for planner
    planner_interval=4                 # Plan every 4 steps
)
```

### Planner Parameters

- `planner_llm`: A LangChain chat model instance used for high-level task planning. Can be a smaller/cheaper model than the main LLM.
- `use_vision_for_planner`: Enable/disable vision capabilities for the planner model. Defaults to `True`.
- `planner_interval`: Number of steps between planning phases. Defaults to `1`.

Using a separate planner model can help:
- Reduce costs by using a smaller model for high-level planning
- Improve task decomposition and strategic thinking
- Better handle complex, multi-step tasks

<Note>
  The planner model is optional. If not specified, the agent will not use the planner model.
</Note>

### Optional Parameters

- `message_context`: Additional information about the task to help the LLM understand the task better.
- `initial_actions`: List of initial actions to run before the main task.
- `max_actions_per_step`: Maximum number of actions to run in a step. Defaults to `10`.
- `max_failures`: Maximum number of failures before giving up. Defaults to `3`.
- `retry_delay`: Time to wait between retries in seconds when rate limited. Defaults to `10`.
- `generate_gif`: Enable/disable GIF generation. Defaults to `False`. Set to `True` or a string path to save the GIF.



================================================
File: docs/customize/browser-settings.mdx
================================================
---
title: "Browser Settings"
description: "Configure browser behavior and context settings"
icon: "globe"
---

Browser Use allows you to customize the browser's behavior through two main configuration classes: `BrowserConfig` and `BrowserContextConfig`. These settings control everything from headless mode to proxy settings and page load behavior.

<Note>
  We are currently working on improving how browser contexts are managed. The
  system will soon transition to a "1 agent, 1 browser, 1 context" model for
  better stability and developer experience.
</Note>

# Browser Configuration

The `BrowserConfig` class controls the core browser behavior and connection settings.

```python
from browser_use import BrowserConfig

# Basic configuration
config = BrowserConfig(
    headless=False,
    disable_security=True
)

browser = Browser(config=config)

agent = Agent(
    browser=browser,
    # ...
)
```

## Core Settings

- **headless** (default: `False`)
  Runs the browser without a visible UI. Note that some websites may detect headless mode.

- **disable_security** (default: `True`)
  Disables browser security features. While this can fix certain functionality issues (like cross-site iFrames), it should be used cautiously, especially when visiting untrusted websites.

### Additional Settings

- **extra_chromium_args** (default: `[]`)
  Additional arguments are passed to the browser at launch. See the [full list of available arguments](https://github.com/browser-use/browser-use/blob/main/browser_use/browser/browser.py#L180).

- **proxy** (default: `None`)
  Standard Playwright proxy settings for using external proxy services.

- **new_context_config** (default: `BrowserContextConfig()`)
  Default settings for new browser contexts. See Context Configuration below.

<Note>
  For web scraping tasks on sites that restrict automated access, we recommend
  using external browser or proxy providers for better reliability.
</Note>

## Alternative Initialization

These settings allow you to connect to external browser providers or use a local Chrome instance.

### External Browser Provider (wss)

Connect to cloud-based browser services for enhanced reliability and proxy capabilities.

```python
config = BrowserConfig(
    wss_url="wss://your-browser-provider.com/ws"
)
```

- **wss_url** (default: `None`)
  WebSocket URL for connecting to external browser providers (e.g., [anchorbrowser.io](https://anchorbrowser.io), steel.dev, browserbase.com, browserless.io, [TestingBot](https://testingbot.com/support/ai/integrations/browser-use)).

<Note>
  This overrides local browser settings and uses the provider's configuration.
  Refer to their documentation for settings.
</Note>

### External Browser Provider (cdp)

Connect to cloud or local Chrome instances using Chrome DevTools Protocol (CDP) for use with tools like `headless-shell` or `browserless`.

```python
config = BrowserConfig(
    cdp_url="http://localhost:9222"
)
```

- **cdp_url** (default: `None`)
  URL for connecting to a Chrome instance via CDP. Commonly used for debugging or connecting to locally running Chrome instances.

### Local Chrome Instance (binary)

Connect to your existing Chrome installation to access saved states and cookies.

```python
config = BrowserConfig(
    chrome_instance_path="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome"
)
```

- **chrome_instance_path** (default: `None`)
  Path to connect to an existing Chrome installation. Particularly useful for workflows requiring existing login states or browser preferences.

<Note>This will overwrite other browser settings.</Note>

# Context Configuration

The `BrowserContextConfig` class controls settings for individual browser contexts.

```python
from browser_use.browser.context import BrowserContextConfig

config = BrowserContextConfig(
    cookies_file="path/to/cookies.json",
    wait_for_network_idle_page_load_time=3.0,
    browser_window_size={'width': 1280, 'height': 1100},
    locale='en-US',
    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/85.0.4183.102 Safari/537.36',
    highlight_elements=True,
    viewport_expansion=500,
    allowed_domains=['google.com', 'wikipedia.org'],
)

browser = Browser()
context = BrowserContext(browser=browser, config=config)


async def run_search():
	agent = Agent(
		browser_context=context,
		task='Your task',
		llm=llm)
```

## Configuration Options

### Page Load Settings

- **minimum_wait_page_load_time** (default: `0.5`)
  Minimum time to wait before capturing page state for LLM input.

- **wait_for_network_idle_page_load_time** (default: `1.0`)
  Time to wait for network activity to cease. Increase to 3-5s for slower websites. This tracks essential content loading, not dynamic elements like videos.

- **maximum_wait_page_load_time** (default: `5.0`)
  Maximum time to wait for page load before proceeding.

### Display Settings

- **browser_window_size** (default: `{'width': 1280, 'height': 1100}`)
  Browser window dimensions. The default size is optimized for general use cases and interaction with common UI elements like cookie banners.

- **locale** (default: `None`)
  Specify user locale, for example en-GB, de-DE, etc. Locale will affect the navigator. Language value, Accept-Language request header value as well as number and date formatting rules. If not provided, defaults to the system default locale.

- **highlight_elements** (default: `True`)
  Highlight interactive elements on the screen with colorful bounding boxes.

- **viewport_expansion** (default: `500`)
  Viewport expansion in pixels. With this you can controll how much of the page is included in the context of the LLM. If set to -1, all elements from the entire page will be included (this leads to high token usage). If set to 0, only the elements which are visible in the viewport will be included.
  Default is 500 pixels, that means that we inlcude a little bit more than the visible viewport inside the context.

### Restrict URLs

- **allowed_domains** (default: `None`)
  List of allowed domains that the agent can access. If None, all domains are allowed.
  Example: ['google.com', 'wikipedia.org'] - Here the agent will only be able to access google and wikipedia.

### Debug and Recording

- **save_recording_path** (default: `None`)
  Directory path for saving video recordings.

- **trace_path** (default: `None`)
  Directory path for saving trace files. Files are automatically named as `{trace_path}/{context_id}.zip`.



================================================
File: docs/customize/custom-functions.mdx
================================================
---
title: "Custom Functions"
description: "Extend default agent and write custom function calls"
icon: "function"
---

## Basic Function Registration

Functions can be either `sync` or `async`. Keep them focused and single-purpose.

```python
from browser_use import Controller, ActionResult
# Initialize the controller
controller = Controller()

@controller.action('Ask user for information')
def ask_human(question: str) -> str:
    answer = input(f'\n{question}\nInput: ')
    return ActionResult(extracted_content=answer)
```

<Note>
  Basic `Controller` has all basic functionality you might need to interact with
  the browser already implemented.
</Note>

```python
# ... then pass controller to the agent
agent = Agent(
    task=task,
    llm=llm,
    controller=controller
)
```

<Note>
  Keep the function name and description short and concise. The Agent use the
  function solely based on the name and description. The stringified output of
  the action is passed to the Agent.
</Note>

## Browser-Aware Functions

For actions that need browser access, simply add the `browser` parameter inside the function parameters:

```python
from browser_use import Browser, Controller, ActionResult

controller = Controller()
@controller.action('Open website')
async def open_website(url: str, browser: Browser):
    page = browser.get_current_page()
    await page.goto(url)
    return ActionResult(extracted_content='Website opened')
```

## Structured Parameters with Pydantic

For complex actions, you can define parameter schemas using Pydantic models:

```python
from pydantic import BaseModel
from typing import Optional
from browser_use import Controller, ActionResult, Browser

controller = Controller()

class JobDetails(BaseModel):
    title: str
    company: str
    job_link: str
    salary: Optional[str] = None

@controller.action(
    'Save job details which you found on page',
    param_model=JobDetails
)
async def save_job(params: JobDetails, browser: Browser):
    print(f"Saving job: {params.title} at {params.company}")

    # Access browser if needed
    page = browser.get_current_page()
    await page.goto(params.job_link)
```

## Using Custom Actions with multiple agents

You can use the same controller for multiple agents.

```python
controller = Controller()

# ... register actions to the controller

agent = Agent(
    task="Go to website X and find the latest news",
    llm=llm,
    controller=controller
)

# Run the agent
await agent.run()

agent2 = Agent(
    task="Go to website Y and find the latest news",
    llm=llm,
    controller=controller
)

await agent2.run()
```

<Note>
  The controller is stateless and can be used to register multiple actions and
  multiple agents.
</Note>



## Exclude functions
If you want less actions to be used by the agent, you can exclude them from the controller.
```python
controller = Controller(exclude_actions=['open_tab', 'search_google'])
```


For more examples like file upload or notifications, visit [examples/custom-functions](https://github.com/browser-use/browser-use/tree/main/examples/custom-functions).




================================================
File: docs/customize/output-format.mdx
================================================
---
title: "Output Format"
description: "The default is text. But you can define a structured output format to make post-processing easier."
icon: "code"
---

## Custom output format
With [this example](https://github.com/browser-use/browser-use/blob/main/examples/features/custom_output.py) you can define what output format the agent should return to you.

```python
from pydantic import BaseModel
# Define the output format as a Pydantic model
class Post(BaseModel):
	post_title: str
	post_url: str
	num_comments: int
	hours_since_post: int


class Posts(BaseModel):
	posts: List[Post]


controller = Controller(output_model=Posts)


async def main():
	task = 'Go to hackernews show hn and give me the first  5 posts'
	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(task=task, llm=model, controller=controller)

	history = await agent.run()

	result = history.final_result()
	if result:
		parsed: Posts = Posts.model_validate_json(result)

		for post in parsed.posts:
			print('\n--------------------------------')
			print(f'Title:            {post.post_title}')
			print(f'URL:              {post.post_url}')
			print(f'Comments:         {post.num_comments}')
			print(f'Hours since post: {post.hours_since_post}')
	else:
		print('No result')


if __name__ == '__main__':
	asyncio.run(main())
```


================================================
File: docs/customize/real-browser.mdx
================================================
---
title: "Connect to your Browser"
description: "With this you can connect to your real browser, where you are logged in with all your accounts."
icon: "computer"
---

## Overview

You can connect the agent to your real Chrome browser instance, allowing it to access your existing browser profile with all your logged-in accounts and settings. This is particularly useful when you want the agent to interact with services where you're already authenticated.

<Note>
  First make sure to close all running Chrome instances.
</Note>

## Basic Configuration

To connect to your real Chrome browser, you'll need to specify the path to your Chrome executable when creating the Browser instance:

```python
from browser_use import Agent, Browser, BrowserConfig
from langchain_openai import ChatOpenAI
import asyncio
# Configure the browser to connect to your Chrome instance
browser = Browser(
    config=BrowserConfig(
        # Specify the path to your Chrome executable
        chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',  # macOS path
        # For Windows, typically: 'C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe'
        # For Linux, typically: '/usr/bin/google-chrome'
    )
)

# Create the agent with your configured browser
agent = Agent(
    task="Your task here",
    llm=ChatOpenAI(model='gpt-4o'),
    browser=browser,
)

async def main():
    await agent.run()

    input('Press Enter to close the browser...')
    await browser.close()

if __name__ == '__main__':
    asyncio.run(main())
```


<Note>
  When using your real browser, the agent will have access to all your logged-in sessions. Make sure to ALWAYS review the task you're giving to the agent and ensure it aligns with your security requirements!
</Note>



================================================
File: docs/customize/sensitive-data.mdx
================================================
---
title: "Sensitive Data"
description: "Handle sensitive information securely by preventing the model from seeing actual passwords."
icon: "shield"
---

## Handling Sensitive Data

When working with sensitive information like passwords, you can use the `sensitive_data` parameter to prevent the model from seeing the actual values while still allowing it to reference them in its actions.

Here's an example of how to use sensitive data:

```python
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from browser_use import Agent

load_dotenv()

# Initialize the model
llm = ChatOpenAI(
    model='gpt-4o',
    temperature=0.0,
)

# Define sensitive data
# The model will only see the keys (x_name, x_password) but never the actual values
sensitive_data = {'x_name': 'magnus', 'x_password': '12345678'}

# Use the placeholder names in your task description
task = 'go to x.com and login with x_name and x_password then write a post about the meaning of life'

# Pass the sensitive data to the agent
agent = Agent(task=task, llm=llm, sensitive_data=sensitive_data)

async def main():
    await agent.run()

if __name__ == '__main__':
    asyncio.run(main())
```

In this example:
1. The model only sees `x_name` and `x_password` as placeholders.
2. When the model wants to use your password it outputs x_password - and we replace it with the actual value.
3. When your password is visable on the current page, we replace it in the LLM input - so that the model never has it in its state. 

Warning: Vision models still see the image of the page - where the sensitive data might be visible.

This approach ensures that sensitive information remains secure while still allowing the agent to perform tasks that require authentication.


================================================
File: docs/customize/supported-models.mdx
================================================
---
title: "Supported Models"
description: "Guide to using different LangChain chat models with Browser Use"
icon: "robot"
---

## Overview

Browser Use supports various LangChain chat models. Here's how to configure and use the most popular ones. The full list is available in the [LangChain documentation](https://python.langchain.com/docs/integrations/chat/).

## Model Recommendations

We have yet to test performance across all models. Currently, we achieve the best results using GPT-4o with an 89% accuracy on the [WebVoyager Dataset](https://browser-use.com/posts/sota-technical-report). DeepSeek-V3 is 30 times cheaper than GPT-4o. Gemini-2.0-exp is also gaining popularity in the community because it is currently free.
We also support local models, like Qwen 2.5, but be aware that small models often return the wrong output structure-which lead to parsing errors. We believe that local models will improve significantly this year.


<Note>
  All models require their respective API keys. Make sure to set them in your
  environment variables before running the agent.
</Note>

## Supported Models

All LangChain chat models, which support tool-calling are available. We will document the most popular ones here.

### OpenAI

OpenAI's GPT-4o models are recommended for best performance.

```python
from langchain_openai import ChatOpenAI
from browser_use import Agent

# Initialize the model
llm = ChatOpenAI(
    model="gpt-4o",
    temperature=0.0,
)

# Create agent with the model
agent = Agent(
    task="Your task here",
    llm=llm
)
```

Required environment variables:

```bash .env
OPENAI_API_KEY=
```

### Anthropic


```python
from langchain_anthropic import ChatAnthropic
from browser_use import Agent

# Initialize the model
llm = ChatAnthropic(
    model_name="claude-3-5-sonnet-20240620",
    temperature=0.0,
    timeout=100, # Increase for complex tasks
)

# Create agent with the model
agent = Agent(
    task="Your task here",
    llm=llm
)
```

And add the variable:

```bash .env
ANTHROPIC_API_KEY=
```

### Azure OpenAI

```python
from langchain_openai import AzureChatOpenAI
from browser_use import Agent
from pydantic import SecretStr
import os

# Initialize the model
llm = AzureChatOpenAI(
    model="gpt-4o",
    api_version='2024-10-21',
    azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),
    api_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),
)

# Create agent with the model
agent = Agent(
    task="Your task here",
    llm=llm
)
```

Required environment variables:

```bash .env
AZURE_OPENAI_ENDPOINT=https://your-endpoint.openai.azure.com/
AZURE_OPENAI_KEY=
```


### Gemini

```python
from langchain_google_genai import ChatGoogleGenerativeAI
from browser_use import Agent
from pydantic import SecretStr
import os
from dotenv import load_dotenv
load_dotenv()

api_key = os.getenv("GEMINI_API_KEY")

# Initialize the model
llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=SecretStr(os.getenv('GEMINI_API_KEY')))

# Create agent with the model
agent = Agent(
    task="Your task here",
    llm=llm
)
```

Required environment variables:

```bash .env
GEMINI_API_KEY=
```


### DeepSeek-V3
The community likes DeepSeek-V3 for its low price, no rate limits, open-source nature, and good performance. 
The example is available [here](https://github.com/browser-use/browser-use/blob/main/examples/models/deepseek.py).

```python
from langchain_openai import ChatOpenAI
from browser_use import Agent
from pydantic import SecretStr


# Initialize the model
llm=ChatOpenAI(base_url='https://api.deepseek.com/v1', model='deepseek-chat', api_key=SecretStr(api_key))

# Create agent with the model
agent = Agent(
    task="Your task here",
    llm=llm,
    use_vision=False
)
```

Required environment variables:

```bash .env
DEEPSEEK_API_KEY=
```

### DeepSeek-R1
We support DeepSeek-R1. Its not fully tested yet, more and more functionality will be added, like e.g. the output of it'sreasoning content.
The example is available [here](https://github.com/browser-use/browser-use/blob/main/examples/models/deepseek-r1.py).
It does not support vision. The model is open-source so you could also use it with Ollama, but we have not tested it.
```python
from langchain_openai import ChatOpenAI
from browser_use import Agent
from pydantic import SecretStr


# Initialize the model
llm=ChatOpenAI(base_url='https://api.deepseek.com/v1', model='deepseek-reasoner', api_key=SecretStr(api_key))

# Create agent with the model
agent = Agent(
    task="Your task here",
    llm=llm,
    use_vision=False
)
```

Required environment variables:

```bash .env
DEEPSEEK_API_KEY=
```

### Ollama
Many users asked for local models. Here they are. 

1. Download Ollama from [here](https://ollama.ai/download)
2. Run `ollama pull model_name`. Pick a model which supports tool-calling from [here](https://ollama.com/search?c=tools)
3. Run `ollama start`

```python
from langchain_ollama import ChatOllama
from browser_use import Agent
from pydantic import SecretStr


# Initialize the model
llm=ChatOllama(model="qwen2.5", num_ctx=32000)

# Create agent with the model
agent = Agent(
    task="Your task here",
    llm=llm
)
```

Required environment variables: None!

## Coming soon
(We are working on it)
- Groq
- Github
- Fine-tuned models



================================================
File: docs/customize/system-prompt.mdx
================================================
---
title: "System Prompt"
description: "Customize the system prompt to control agent behavior and capabilities"
icon: "message"
---

## Overview

You can customize the system prompt in two ways:

1. Extend the default system prompt with additional instructions
2. Override the default system prompt entirely

<Note>
  Custom system prompts allow you to modify the agent's behavior at a
  fundamental level. Use this feature carefully as it can significantly impact
  the agent's performance and reliability.
</Note>

### Extend System Prompt (recommended)

To add additional instructions to the default system prompt:

```python
from browser_use import Agent
from langchain_openai import ChatOpenAI

# Add your custom instructions
extend_system_message = """
REMEMBER the most important RULE:
ALWAYS open first a new tab and go first to url wikipedia.com no matter the task!!!
"""

# Create agent with extended system prompt
agent = Agent(
    task="Your task here",
    llm=ChatOpenAI(model='gpt-4'),
    extend_system_message=extend_system_message
)
```

### Override System Prompt

<Warning>
  Not recommended! If you must override the [default system
  prompt](https://github.com/browser-use/browser-use/blob/main/browser_use/agent/system_prompt.md),
  make sure to test the agent yourself.
</Warning>

Anyway, to override the default system prompt:

```python
# Define your complete custom prompt
override_system_message = """
You are an AI agent that helps users with web browsing tasks.

[Your complete custom instructions here...]
"""

# Create agent with custom system prompt
agent = Agent(
    task="Your task here",
    llm=ChatOpenAI(model='gpt-4'),
    override_system_message=override_system_message
)
```



================================================
File: docs/development/contribution-guide.mdx
================================================
---
title: "Contribution Guide"
description: "Learn how to contribute to Browser Use"
icon: "code-pull-request"
---

Working on it!



================================================
File: docs/development/local-setup.mdx
================================================
---
title: "Local Setup"
description: "Set up Browser Use development environment locally"
icon: "laptop-code"
---

## Prerequisites

Browser Use requires Python 3.11 or higher. We recommend using [uv](https://docs.astral.sh/uv/) for Python environment management.

## Clone the Repository

First, clone the Browser Use repository:

```bash
git clone https://github.com/browser-use/browser-use
cd browser-use
```

## Environment Setup

1. Create a virtual environment:

```bash
uv venv --python 3.11
```

2. Install dependencies:

```bash
# Install the package in editable mode with all development dependencies
uv pip install -e ".[dev]"
```

<Note>
  The `-e` flag installs the package in "editable" mode, which means your local code changes
  will be reflected immediately without requiring reinstallation. The `[dev]` part installs
  additional dependencies needed for development.
</Note>

## Configuration

Set up your environment variables:

```bash
# Copy the example environment file
cp .env.example .env
```

Or manually create a `.env` file with your API keys:

```bash .env
OPENAI_API_KEY=
ANTHROPIC_API_KEY=
```

<Note>
  You can use any LLM model supported by LangChain. See [LangChain
  Models](/customize/supported-models) for available options and their specific
  API key requirements.
</Note>

## Development

After setup, you can:

- Run tests with `pytest`
- Build the package with `hatch build`
- Try the examples in the `examples/` directory

## Getting Help

If you run into any issues:

1. Check our [GitHub Issues](https://github.com/browser-use/browser-use/issues)
2. Join our [Discord community](https://link.browser-use.com/discord) for support

<Note>
  We welcome contributions! See our [Contribution
  Guide](/development/contribution-guide) for guidelines on how to help improve
  Browser Use.
</Note>



================================================
File: docs/development/observability.mdx
================================================
---
title: "Observability"
description: "Trace Browser Use's agent execution steps and browser sessions"
icon: "eye"
---

## Overview

Browser Use has a native integration with [Laminar](https://lmnr.ai) - open-source platform for tracing, evals and labeling of AI agents.
Read more about Laminar in the [Laminar docs](https://docs.lmnr.ai).

<Note>
  Laminar excels at tracing browser agents by providing unified visibility into both browser session recordings and agent execution steps.
</Note>

## Setup

To setup Laminar, you need to install the `lmnr` package and set the `LMNR_PROJECT_API_KEY` environment variable.

To get your project API key, you can either:
- Register on [Laminar Cloud](https://lmnr.ai) and get the key from your project settings
- Or spin up a local Laminar instance and get the key from the settings page

```bash
pip install 'lmnr[all]'
export LMNR_PROJECT_API_KEY=<your-project-api-key>
```

## Usage

Then, you simply initialize the Laminar at the top of your project and both Browser Use and session recordings will be automatically traced.

```python {5-8}
from langchain_openai import ChatOpenAI
from browser_use import Agent
import asyncio

from lmnr import Laminar
# this line auto-instruments Browser Use and any browser you use (local or remote)
Laminar.initialize(project_api_key="...") # you can also pass project api key here

async def main():
    agent = Agent(
        task="open google, search Laminar AI",
        llm=ChatOpenAI(model="gpt-4o-mini"),
    )
    result = await agent.run()
    print(result)

asyncio.run(main())
```

## Viewing Traces

You can view traces in the Laminar UI by going to the traces tab in your project.
When you select a trace, you can see both the browser session recording and the agent execution steps.

Timeline of the browser session is synced with the agent execution steps, timeline highlights indicate the agent's current step synced with the browser session.
In the trace view, you can also see the agent's current step, the tool it's using, and the tool's input and output. Tools are highlighted in the timeline with a yellow color.

<img className="block" src="/images/laminar.png" alt="Laminar" />


## Laminar

To learn more about tracing and evaluating your browser agents, check out the [Laminar docs](https://docs.lmnr.ai).


================================================
File: docs/development/roadmap.mdx
================================================
---
title: "Roadmap"
description: "Future plans and upcoming features for Browser Use"
icon: "road"
---

Big things coming soon!



================================================
File: docs/development/telemetry.mdx
================================================
---
title: "Telemetry"
description: "Understanding Browser Use's telemetry and privacy settings"
icon: "chart-mixed"
---

## Overview

Browser Use collects anonymous usage data to help us understand how the library is being used and to improve the user experience. It also helps us fix bugs faster and prioritize feature development.

## Data Collection

We use [PostHog](https://posthog.com) for telemetry collection. The data is completely anonymized and contains no personally identifiable information.

<Note>
  We never collect personal information, credentials, or specific content from
  your browser automation tasks.
</Note>

## Opting Out

You can disable telemetry by setting an environment variable:

```bash .env
ANONYMIZED_TELEMETRY=false
```

Or in your Python code:

```python
import os
os.environ["ANONYMIZED_TELEMETRY"] = "false"
```

<Note>
  Even when enabled, telemetry has zero impact on the library's performance or
  functionality. Code is available in [Telemetry
  Service](https://github.com/browser-use/browser-use/tree/main/browser_use/telemetry).
</Note>





================================================
File: examples/simple.py
================================================
import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use import Agent

load_dotenv()

# Initialize the model
llm = ChatOpenAI(
	model='gpt-4o',
	temperature=0.0,
)
task = 'Find the founders of browser-use and draft them a short personalized message'

agent = Agent(task=task, llm=llm)


async def main():
	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/browser/real_browser.py
================================================
import os
import sys
from pathlib import Path

from browser_use.agent.views import ActionResult

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio

from langchain_openai import ChatOpenAI

from browser_use import Agent, Controller
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.browser.context import BrowserContext

browser = Browser(
	config=BrowserConfig(
		# NOTE: you need to close your chrome browser - so that this can open your browser in debug mode
		chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
	)
)


async def main():
	agent = Agent(
		task='In docs.google.com write my Papa a quick letter',
		llm=ChatOpenAI(model='gpt-4o'),
		browser=browser,
	)

	await agent.run()
	await browser.close()

	input('Press Enter to close...')


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/browser/using_cdp.py
================================================
"""
Simple demonstration of the CDP feature.

To test this locally, follow these steps:
1. Create a shortcut for the executable Chrome file.
2. Add the following argument to the shortcut:
   - On Windows: `--remote-debugging-port=9222`
3. Open a web browser and navigate to `http://localhost:9222/json/version` to verify that the Remote Debugging Protocol (CDP) is running.
4. Launch this example.

@dev You need to set the `GEMINI_API_KEY` environment variable before proceeding.
"""

import os
import sys

from dotenv import load_dotenv
from pydantic import SecretStr

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio

from langchain_google_genai import ChatGoogleGenerativeAI

from browser_use import Agent, Controller
from browser_use.browser.browser import Browser, BrowserConfig

load_dotenv()
api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
	raise ValueError('GEMINI_API_KEY is not set')

browser = Browser(
	config=BrowserConfig(
		headless=False,
		cdp_url='http://localhost:9222',
	)
)
controller = Controller()


async def main():
	task = 'In docs.google.com write my Papa a quick thank you for everything letter \n - Magnus'
	task += ' and save the document as pdf'
	model = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=SecretStr(str(api_key)))
	agent = Agent(
		task=task,
		llm=model,
		controller=controller,
		browser=browser,
	)

	await agent.run()
	await browser.close()

	input('Press Enter to close...')


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/custom-functions/advanced_search.py
================================================
import json
import os
import sys

import requests

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from browser_use import ActionResult, Agent, Controller

load_dotenv()


class Person(BaseModel):
	name: str
	email: str | None = None


class PersonList(BaseModel):
	people: list[Person]


controller = Controller(exclude_actions=['search_google'], output_model=PersonList)
BEARER_TOKEN = os.getenv('BEARER_TOKEN')

if not BEARER_TOKEN:
	# use the api key for ask tessa
	# you can also use other apis like exa, xAI, perplexity, etc.
	raise ValueError('BEARER_TOKEN is not set - go to https://www.heytessa.ai/ and create an api key')


@controller.registry.action('Search the web for a specific query')
async def search_web(query: str):
	keys_to_use = ['url', 'title', 'content', 'author', 'score']
	headers = {'Authorization': f'Bearer {BEARER_TOKEN}'}
	response = requests.post('https://asktessa.ai/api/search', headers=headers, json={'query': query})

	final_results = [
		{key: source[key] for key in keys_to_use if key in source}
		for source in response.json()['sources']
		if source['score'] >= 0.8
	]
	# print(json.dumps(final_results, indent=4))
	result_text = json.dumps(final_results, indent=4)
	print(result_text)
	return ActionResult(extracted_content=result_text, include_in_memory=True)


names = [
	'Ruedi Aebersold',
	'Bernd Bodenmiller',
	'Eugene Demler',
	'Erich Fischer',
	'Pietro Gambardella',
	'Matthias Huss',
	'Reto Knutti',
	'Maksym Kovalenko',
	'Antonio Lanzavecchia',
	'Maria Lukatskaya',
	'Jochen Markard',
	'Javier P√©rez-Ram√≠rez',
	'Federica Sallusto',
	'Gisbert Schneider',
	'Sonia I. Seneviratne',
	'Michael Siegrist',
	'Johan Six',
	'Tanja Stadler',
	'Shinichi Sunagawa',
	'Michael Bruce Zimmermann',
]


async def main():
	task = 'use search_web with "find email address of the following ETH professor:" for each of the following persons in a list of actions. Finally return the list with name and email if provided'
	task += '\n' + '\n'.join(names)
	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(task=task, llm=model, controller=controller, max_actions_per_step=20)

	history = await agent.run()

	result = history.final_result()
	if result:
		parsed: PersonList = PersonList.model_validate_json(result)

		for person in parsed.people:
			print(f'{person.name} - {person.email}')
	else:
		print('No result')


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/custom-functions/clipboard.py
================================================
import os
import sys
from pathlib import Path

from browser_use.agent.views import ActionResult

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio

import pyperclip
from langchain_openai import ChatOpenAI

from browser_use import Agent, Controller
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.browser.context import BrowserContext

browser = Browser(
	config=BrowserConfig(
		headless=False,
	)
)
controller = Controller()


@controller.registry.action('Copy text to clipboard')
def copy_to_clipboard(text: str):
	pyperclip.copy(text)
	return ActionResult(extracted_content=text)


@controller.registry.action('Paste text from clipboard')
async def paste_from_clipboard(browser: BrowserContext):
	text = pyperclip.paste()
	# send text to browser
	page = await browser.get_current_page()
	await page.keyboard.type(text)

	return ActionResult(extracted_content=text)


async def main():
	task = f'Copy the text "Hello, world!" to the clipboard, then go to google.com and paste the text'
	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(
		task=task,
		llm=model,
		controller=controller,
		browser=browser,
	)

	await agent.run()
	await browser.close()

	input('Press Enter to close...')


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/custom-functions/file_upload.py
================================================
import os
import sys
from pathlib import Path

from browser_use.agent.views import ActionResult

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio
import logging

from langchain_openai import ChatOpenAI

from browser_use import Agent, Controller
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.browser.context import BrowserContext

logger = logging.getLogger(__name__)

# Initialize controller first
browser = Browser(
	config=BrowserConfig(
		headless=False,
		chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
	)
)
controller = Controller()


@controller.action(
	'Upload file to interactive element with file path ',
)
async def upload_file(index: int, path: str, browser: BrowserContext, available_file_paths: list[str]):
	if path not in available_file_paths:
		return ActionResult(error=f'File path {path} is not available')

	if not os.path.exists(path):
		return ActionResult(error=f'File {path} does not exist')

	dom_el = await browser.get_dom_element_by_index(index)

	file_upload_dom_el = dom_el.get_file_upload_element()

	if file_upload_dom_el is None:
		msg = f'No file upload element found at index {index}'
		logger.info(msg)
		return ActionResult(error=msg)

	file_upload_el = await browser.get_locate_element(file_upload_dom_el)

	if file_upload_el is None:
		msg = f'No file upload element found at index {index}'
		logger.info(msg)
		return ActionResult(error=msg)

	try:
		await file_upload_el.set_input_files(path)
		msg = f'Successfully uploaded file to index {index}'
		logger.info(msg)
		return ActionResult(extracted_content=msg, include_in_memory=True)
	except Exception as e:
		msg = f'Failed to upload file to index {index}: {str(e)}'
		logger.info(msg)
		return ActionResult(error=msg)


@controller.action('Read the file content of a file given a path')
async def read_file(path: str, available_file_paths: list[str]):
	if path not in available_file_paths:
		return ActionResult(error=f'File path {path} is not available')

	with open(path, 'r') as f:
		content = f.read()
	msg = f'File content: {content}'
	logger.info(msg)
	return ActionResult(extracted_content=msg, include_in_memory=True)


def create_file(file_type: str = 'txt'):
	with open(f'tmp.{file_type}', 'w') as f:
		f.write('test')
	file_path = Path.cwd() / f'tmp.{file_type}'
	logger.info(f'Created file: {file_path}')
	return str(file_path)


async def main():
	task = f'Go to https://kzmpmkh2zfk1ojnpxfn1.lite.vusercontent.net/ and - read the file content and upload them to fields'

	available_file_paths = [create_file('txt'), create_file('pdf'), create_file('csv')]

	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(
		task=task,
		llm=model,
		controller=controller,
		browser=browser,
		available_file_paths=available_file_paths,
	)

	await agent.run()

	await browser.close()

	input('Press Enter to close...')


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/custom-functions/notification.py
================================================
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from browser_use import ActionResult, Agent, Controller

load_dotenv()

controller = Controller()


@controller.registry.action('Done with task ')
async def done(text: str):
	import yagmail

	# To send emails use
	# STEP 1: go to https://support.google.com/accounts/answer/185833
	# STEP 2: Create an app password (you cant use here your normal gmail password)
	# STEP 3: Use the app password in the code below for the password
	yag = yagmail.SMTP('your_email@gmail.com', 'your_app_password')
	yag.send(
		to='recipient@example.com',
		subject='Test Email',
		contents=f'result\n: {text}',
	)

	return ActionResult(is_done=True, extracted_content='Email sent!')


async def main():
	task = 'go to brower-use.com and then done'
	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(task=task, llm=model, controller=controller)

	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/custom-functions/save_to_file_hugging_face.py
================================================
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
from typing import List, Optional

from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from browser_use.agent.service import Agent
from browser_use.controller.service import Controller

# Initialize controller first
controller = Controller()


class Model(BaseModel):
	title: str
	url: str
	likes: int
	license: str


class Models(BaseModel):
	models: List[Model]


@controller.action('Save models', param_model=Models)
def save_models(params: Models):
	with open('models.txt', 'a') as f:
		for model in params.models:
			f.write(f'{model.title} ({model.url}): {model.likes} likes, {model.license}\n')


# video: https://preview.screen.studio/share/EtOhIk0P
async def main():
	task = f'Look up models with a license of cc-by-sa-4.0 and sort by most likes on Hugging face, save top 5 to file.'

	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(task=task, llm=model, controller=controller)

	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/custom_output.py
================================================
"""
Show how to use custom outputs.

@dev You need to add OPENAI_API_KEY to your environment variables.
"""

import os
import sys
from typing import List

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from browser_use import ActionResult, Agent, Controller

load_dotenv()


class Post(BaseModel):
	post_title: str
	post_url: str
	num_comments: int
	hours_since_post: int


class Posts(BaseModel):
	posts: List[Post]


controller = Controller(output_model=Posts)


async def main():
	task = 'Go to hackernews show hn and give me the first  5 posts'
	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(task=task, llm=model, controller=controller)

	history = await agent.run()

	result = history.final_result()
	if result:
		parsed: Posts = Posts.model_validate_json(result)

		for post in parsed.posts:
			print('\n--------------------------------')
			print(f'Title:            {post.post_title}')
			print(f'URL:              {post.post_url}')
			print(f'Comments:         {post.num_comments}')
			print(f'Hours since post: {post.hours_since_post}')
	else:
		print('No result')


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/custom_system_prompt.py
================================================
import json
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from langchain_openai import ChatOpenAI

from browser_use import Agent

extend_system_message = (
	'REMEMBER the most important RULE: ALWAYS open first a new tab and go first to url wikipedia.com no matter the task!!!'
)

# or use override_system_message to completely override the system prompt


async def main():
	task = "do google search to find images of Elon Musk's wife"
	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(task=task, llm=model, extend_system_message=extend_system_message)

	print(
		json.dumps(
			agent.message_manager.system_prompt.model_dump(exclude_unset=True),
			indent=4,
		)
	)

	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/custom_user_agent.py
================================================
import os
import sys

from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI

from browser_use.browser.context import BrowserContext, BrowserContextConfig

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import argparse
import asyncio

from browser_use import Agent
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.controller.service import Controller


def get_llm(provider: str):
	if provider == 'anthropic':
		return ChatAnthropic(model_name='claude-3-5-sonnet-20240620', timeout=25, stop=None, temperature=0.0)
	elif provider == 'openai':
		return ChatOpenAI(model='gpt-4o', temperature=0.0)

	else:
		raise ValueError(f'Unsupported provider: {provider}')


# NOTE: This example is to find your current user agent string to use it in the browser_context
task = 'go to https://whatismyuseragent.com and find the current user agent string '


controller = Controller()


parser = argparse.ArgumentParser()
parser.add_argument('--query', type=str, help='The query to process', default=task)
parser.add_argument(
	'--provider',
	type=str,
	choices=['openai', 'anthropic'],
	default='openai',
	help='The model provider to use (default: openai)',
)

args = parser.parse_args()

llm = get_llm(args.provider)


browser = Browser(
	config=BrowserConfig(
		# chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
	)
)

browser_context = BrowserContext(config=BrowserContextConfig(user_agent='foobarfoo'), browser=browser)

agent = Agent(
	task=args.query,
	llm=llm,
	controller=controller,
	# browser=browser,
	browser_context=browser_context,
	use_vision=True,
	max_actions_per_step=1,
)


async def main():
	await agent.run(max_steps=25)

	input('Press Enter to close the browser...')
	await browser_context.close()


asyncio.run(main())



================================================
File: examples/features/download_file.py
================================================
import asyncio
import os

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import SecretStr

from browser_use import Agent
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.browser.context import BrowserContextConfig

load_dotenv()
api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
	raise ValueError('GEMINI_API_KEY is not set')
llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=SecretStr(api_key))
browser = Browser(
	config=BrowserConfig(
		new_context_config=BrowserContextConfig(save_downloads_path=os.path.join(os.path.expanduser('~'), 'downloads'))
	)
)


async def run_download():
	agent = Agent(
		task=('Go to "https://file-examples.com/" and download the smallest doc file.'),
		llm=llm,
		max_actions_per_step=8,
		use_vision=True,
		browser=browser,
	)
	await agent.run(max_steps=25)
	await browser.close()


if __name__ == '__main__':
	asyncio.run(run_download())



================================================
File: examples/features/follow_up_tasks.py
================================================
import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use import Agent
from browser_use.agent.views import ActionResult
from browser_use.controller.service import Controller

load_dotenv()

# Initialize the model
llm = ChatOpenAI(
	model='gpt-4o',
	temperature=0.0,
)
controller = Controller()


task = 'Find the founders of browser-use and draft them a short personalized message'

agent = Agent(task=task, llm=llm, controller=controller)


async def main():
	await agent.run()

	# new_task = input('Type in a new task: ')
	new_task = 'Find an image of the founders'

	agent.add_new_task(new_task)

	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/initial_actions.py
================================================
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use import Agent

load_dotenv()
llm = ChatOpenAI(model='gpt-4o')

initial_actions = [
	{'open_tab': {'url': 'https://www.google.com'}},
	{'open_tab': {'url': 'https://en.wikipedia.org/wiki/Randomness'}},
	{'scroll_down': {'amount': 1000}},
]
agent = Agent(
	task='What theories are displayed on the page?',
	initial_actions=initial_actions,
	llm=llm,
)


async def main():
	await agent.run(max_steps=10)


if __name__ == '__main__':
	import asyncio

	asyncio.run(main())



================================================
File: examples/features/multi-tab_handling.py
================================================
"""
Simple try of the agent.

@dev You need to add OPENAI_API_KEY to your environment variables.
"""

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from langchain_openai import ChatOpenAI

from browser_use import Agent

# video: https://preview.screen.studio/share/clenCmS6
llm = ChatOpenAI(model='gpt-4o')
agent = Agent(
	task='open 3 tabs with elon musk, trump, and steve jobs, then go back to the first and stop',
	llm=llm,
)


async def main():
	await agent.run()


asyncio.run(main())



================================================
File: examples/features/multiple_agents_same_browser.py
================================================
import os
import sys

from langchain_openai import ChatOpenAI

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from browser_use import Agent, Browser, Controller


# Video: https://preview.screen.studio/share/8Elaq9sm
async def main():
	# Persist the browser state across agents

	browser = Browser()
	async with await browser.new_context() as context:
		model = ChatOpenAI(model='gpt-4o')
		current_agent = None

		async def get_input():
			return await asyncio.get_event_loop().run_in_executor(
				None, lambda: input('Enter task (p: pause current agent, r: resume, b: break): ')
			)

		while True:
			task = await get_input()

			if task.lower() == 'p':
				# Pause the current agent if one exists
				if current_agent:
					current_agent.pause()
				continue
			elif task.lower() == 'r':
				# Resume the current agent if one exists
				if current_agent:
					current_agent.resume()
				continue
			elif task.lower() == 'b':
				# Break the current agent's execution if one exists
				if current_agent:
					current_agent.stop()
					current_agent = None
				continue

			# If there's a current agent running, pause it before starting new one
			if current_agent:
				current_agent.pause()

			# Create and run new agent with the task
			current_agent = Agent(
				task=task,
				llm=model,
				browser_context=context,
			)

			# Run the agent asynchronously without blocking
			asyncio.create_task(current_agent.run())


asyncio.run(main())

# Now aad the cheapest to the cart



================================================
File: examples/features/outsource_state.py
================================================
"""
Show how to use custom outputs.

@dev You need to add OPENAI_API_KEY to your environment variables.
"""

import os
import sys

from browser_use.agent.views import AgentState
from browser_use.browser.browser import Browser, BrowserConfig

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use import Agent

load_dotenv()


async def main():
	task = 'Go to hackernews show hn and give me the first  5 posts'

	browser = Browser(
		config=BrowserConfig(
			headless=True,
		)
	)

	browser_context = await browser.new_context()

	agent_state = AgentState()

	for i in range(10):
		agent = Agent(
			task=task,
			llm=ChatOpenAI(model='gpt-4o'),
			browser=browser,
			browser_context=browser_context,
			injected_agent_state=agent_state,
			page_extraction_llm=ChatOpenAI(model='gpt-4o-mini'),
		)

		done, valid = await agent.take_step()
		print(f'Step {i}: Done: {done}, Valid: {valid}')

		if done and valid:
			break

		agent_state.history.history = []

		# Save state to file
		with open('agent_state.json', 'w') as f:
			serialized = agent_state.model_dump_json(exclude={'history'})
			f.write(serialized)

		# Load state back from file
		with open('agent_state.json', 'r') as f:
			loaded_json = f.read()
			agent_state = AgentState.model_validate_json(loaded_json)

		break


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/parallel_agents.py
================================================
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio

from langchain_openai import ChatOpenAI

from browser_use.agent.service import Agent
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.browser.context import BrowserContextConfig

browser = Browser(
	config=BrowserConfig(
		disable_security=True,
		headless=False,
		new_context_config=BrowserContextConfig(save_recording_path='./tmp/recordings'),
	)
)
llm = ChatOpenAI(model='gpt-4o')


async def main():
	agents = [
		Agent(task=task, llm=llm, browser=browser)
		for task in [
			'Search Google for weather in Tokyo',
			'Check Reddit front page title',
			'Look up Bitcoin price on Coinbase',
			'Find NASA image of the day',
			# 'Check top story on CNN',
			# 'Search latest SpaceX launch date',
			# 'Look up population of Paris',
			# 'Find current time in Sydney',
			# 'Check who won last Super Bowl',
			# 'Search trending topics on Twitter',
		]
	]

	await asyncio.gather(*[agent.run() for agent in agents])

	# async with await browser.new_context() as context:
	agentX = Agent(
		task='Go to apple.com and return the title of the page',
		llm=llm,
		browser=browser,
		# browser_context=context,
	)
	await agentX.run()

	await browser.close()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/pause_agent.py
================================================
import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
import threading
import time

from langchain_openai import ChatOpenAI

from browser_use import Agent


class AgentController:
	def __init__(self):
		llm = ChatOpenAI(model='gpt-4o')
		self.agent = Agent(
			task='open in one action https://www.google.com, https://www.wikipedia.org, https://www.youtube.com, https://www.github.com, https://amazon.com',
			llm=llm,
		)
		self.running = False

	async def run_agent(self):
		"""Run the agent"""
		self.running = True
		await self.agent.run()

	def start(self):
		"""Start the agent in a separate thread"""
		loop = asyncio.new_event_loop()
		asyncio.set_event_loop(loop)
		loop.run_until_complete(self.run_agent())

	def pause(self):
		"""Pause the agent"""
		self.agent.pause()

	def resume(self):
		"""Resume the agent"""
		self.agent.resume()

	def stop(self):
		"""Stop the agent"""
		self.agent.stop()
		self.running = False


def print_menu():
	print('\nAgent Control Menu:')
	print('1. Start')
	print('2. Pause')
	print('3. Resume')
	print('4. Stop')
	print('5. Exit')


def main():
	controller = AgentController()
	agent_thread = None

	while True:
		print_menu()
		choice = input('Enter your choice (1-5): ')

		if choice == '1' and not agent_thread:
			print('Starting agent...')
			agent_thread = threading.Thread(target=controller.start)
			agent_thread.start()

		elif choice == '2':
			print('Pausing agent...')
			controller.pause()

		elif choice == '3':
			print('Resuming agent...')
			controller.resume()

		elif choice == '4':
			print('Stopping agent...')
			controller.stop()
			if agent_thread:
				agent_thread.join()
				agent_thread = None

		elif choice == '5':
			print('Exiting...')
			if controller.running:
				controller.stop()
				if agent_thread:
					agent_thread.join()
			break

		time.sleep(0.1)  # Small delay to prevent CPU spinning


if __name__ == '__main__':
	main()



================================================
File: examples/features/planner.py
================================================
import asyncio

from langchain_openai import ChatOpenAI

from browser_use import Agent


llm = ChatOpenAI(model='gpt-4o', temperature=0.0)
planner_llm = ChatOpenAI(
	model='o3-mini',
)
task = 'your task'


agent = Agent(task=task, llm=llm, planner_llm=planner_llm, use_vision_for_planner=False, planner_interval=1)


async def main():
	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/restrict_urls.py
================================================
import os
import sys

from langchain_anthropic import ChatAnthropic
from langchain_openai import ChatOpenAI

from browser_use.browser.context import BrowserContextConfig

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import argparse
import asyncio

from browser_use import Agent
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.controller.service import Controller

llm = ChatOpenAI(model='gpt-4o', temperature=0.0)
task = (
	'go to google.com and search for openai.com and click on the first link then extract content and scroll down - whats there?'
)

allowed_domains = ['google.com']

browser = Browser(
	config=BrowserConfig(
		chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
		new_context_config=BrowserContextConfig(
			allowed_domains=allowed_domains,
		),
	),
)

agent = Agent(
	task=task,
	llm=llm,
	browser=browser,
)


async def main():
	await agent.run(max_steps=25)

	input('Press Enter to close the browser...')
	await browser.close()


asyncio.run(main())



================================================
File: examples/features/result_processing.py
================================================
import os
import sys
from pprint import pprint

from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.browser.context import (
	BrowserContext,
	BrowserContextConfig,
	BrowserContextWindowSize,
)

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio

from langchain_openai import ChatOpenAI

from browser_use import Agent
from browser_use.agent.views import AgentHistoryList
from browser_use.controller.service import Controller

llm = ChatOpenAI(model='gpt-4o')
browser = Browser(
	config=BrowserConfig(
		headless=False,
		disable_security=True,
		extra_chromium_args=['--window-size=2000,2000'],
	)
)


async def main():
	async with await browser.new_context(
		config=BrowserContextConfig(
			trace_path='./tmp/result_processing',
			no_viewport=False,
			browser_window_size=BrowserContextWindowSize(width=1280, height=1000),
		)
	) as browser_context:
		agent = Agent(
			task="go to google.com and type 'OpenAI' click search and give me the first url",
			llm=llm,
			browser_context=browser_context,
		)
		history: AgentHistoryList = await agent.run(max_steps=3)

		print('Final Result:')
		pprint(history.final_result(), indent=4)

		print('\nErrors:')
		pprint(history.errors(), indent=4)

		# e.g. xPaths the model clicked on
		print('\nModel Outputs:')
		pprint(history.model_actions(), indent=4)

		print('\nThoughts:')
		pprint(history.model_thoughts(), indent=4)
	# close browser
	await browser.close()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/save_trace.py
================================================
import os
import sys

from langchain_openai import ChatOpenAI

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio

from browser_use.agent.service import Agent
from browser_use.browser.browser import Browser
from browser_use.browser.context import BrowserContextConfig

llm = ChatOpenAI(model='gpt-4o', temperature=0.0)


async def main():
	browser = Browser()

	async with await browser.new_context(
		config=BrowserContextConfig(trace_path='./tmp/traces/')
	) as context:
		agent = Agent(
			task='Go to hackernews, then go to apple.com and return all titles of open tabs',
			llm=llm,
			browser_context=context,
		)
		await agent.run()

	await browser.close()


asyncio.run(main())



================================================
File: examples/features/sensitive_data.py
================================================
import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use import Agent

load_dotenv()

# Initialize the model
llm = ChatOpenAI(
	model='gpt-4o',
	temperature=0.0,
)
# the model will see x_name and x_password, but never the actual values.
sensitive_data = {'x_name': 'my_x_name', 'x_password': 'my_x_password'}
task = 'go to x.com and login with x_name and x_password then find interesting posts and like them'

agent = Agent(task=task, llm=llm, sensitive_data=sensitive_data)


async def main():
	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/small_model_for_extraction.py
================================================
import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use import Agent
from browser_use.controller.service import Controller

load_dotenv()

llm = ChatOpenAI(model='gpt-4o', temperature=0.0)
small_llm = ChatOpenAI(model='gpt-4o-mini', temperature=0.0)
task = 'Find the founders of browser-use in ycombinator, extract all links and open the links one by one'
agent = Agent(task=task, llm=llm, page_extraction_llm=small_llm)


async def main():
	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/features/validate_output.py
================================================
"""
Demostrate output validator.

@dev You need to add OPENAI_API_KEY to your environment variables.
"""

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from browser_use import ActionResult, Agent, Controller

load_dotenv()

controller = Controller()


class DoneResult(BaseModel):
	title: str
	comments: str
	hours_since_start: int


# we overwrite done() in this example to demonstrate the validator
@controller.registry.action('Done with task', param_model=DoneResult)
async def done(params: DoneResult):
	result = ActionResult(is_done=True, extracted_content=params.model_dump_json())
	print(result)
	# NOTE: this is clearly wrong - to demonstrate the validator
	return 'blablabla'


async def main():
	task = 'Go to hackernews hn and give me the top 1 post'
	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(task=task, llm=model, controller=controller, validate_output=True)
	# NOTE: this should fail to demonstrate the validator
	await agent.run(max_steps=5)


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/integrations/discord/discord_api.py
================================================
import discord
from discord.ext import commands
from dotenv import load_dotenv
from langchain_core.language_models.chat_models import BaseChatModel

from browser_use import BrowserConfig
from browser_use.agent.service import Agent, Browser

load_dotenv()


class DiscordBot(commands.Bot):
	"""Discord bot implementation for Browser-Use tasks.

	This bot allows users to run browser automation tasks through Discord messages.
	Processes tasks asynchronously and sends the result back to the user in response to the message.
	Messages must start with the configured prefix (default: "$bu") followed by the task description.

	Args:
	    llm (BaseChatModel): Language model instance to use for task processing
	    prefix (str, optional): Command prefix for triggering browser tasks. Defaults to "$bu"
	    ack (bool, optional): Whether to acknowledge task receipt with a message. Defaults to False
	    browser_config (BrowserConfig, optional): Browser configuration settings.
	        Defaults to headless mode

	Usage:
	    ```python
	    from langchain_openai import ChatOpenAI

	    llm = ChatOpenAI()
	    bot = DiscordBot(llm=llm, prefix='$bu', ack=True)
	    bot.run('YOUR_DISCORD_TOKEN')
	    ```

	Discord Usage:
	    Send messages starting with the prefix:
	    "$bu search for python tutorials"
	"""

	def __init__(
		self,
		llm: BaseChatModel,
		prefix: str = '$bu',
		ack: bool = False,
		browser_config: BrowserConfig = BrowserConfig(headless=True),
	):
		self.llm = llm
		self.prefix = prefix.strip()
		self.ack = ack
		self.browser_config = browser_config

		# Define intents.
		intents = discord.Intents.default()
		intents.message_content = True  # Enable message content intent
		intents.members = True  # Enable members intent for user info

		# Initialize the bot with a command prefix and intents.
		super().__init__(
			command_prefix='!', intents=intents
		)  # You may not need prefix, just here for flexibility

		# self.tree = app_commands.CommandTree(self) # Initialize command tree for slash commands.

	async def on_ready(self):
		"""Called when the bot is ready."""
		try:
			print(f'We have logged in as {self.user}')
			cmds = await self.tree.sync()  # Sync the command tree with discord

		except Exception as e:
			print(f'Error during bot startup: {e}')

	async def on_message(self, message):
		"""Called when a message is received."""
		try:
			if message.author == self.user:  # Ignore the bot's messages
				return
			if message.content.strip().startswith(f'{self.prefix} '):
				if self.ack:
					try:
						await message.reply(
							'Starting browser use task...',
							mention_author=True,  # Don't ping the user
						)
					except Exception as e:
						print(f'Error sending start message: {e}')

				try:
					agent_message = await self.run_agent(
						message.content.replace(f'{self.prefix} ', '').strip()
					)
					await message.channel.send(
						content=f'{agent_message}', reference=message, mention_author=True
					)
				except Exception as e:
					await message.channel.send(
						content=f'Error during task execution: {str(e)}',
						reference=message,
						mention_author=True,
					)

		except Exception as e:
			print(f'Error in message handling: {e}')

	#    await self.process_commands(message)  # Needed to process bot commands

	async def run_agent(self, task: str) -> str:
		try:
			browser = Browser(config=self.browser_config)
			agent = Agent(task=(task), llm=self.llm, browser=browser)
			result = await agent.run()

			agent_message = None
			if result.is_done():
				agent_message = result.history[-1].result[0].extracted_content

			if agent_message is None:
				agent_message = 'Oops! Something went wrong while running Browser-Use.'

			return agent_message

		except Exception as e:
			raise Exception(f'Browser-use task failed: {str(e)}')



================================================
File: examples/integrations/discord/discord_example.py
================================================
"""
This examples requires you to have a Discord bot token and the bot already added to a server.

Five Steps to create and invite a Discord bot:

1. Create a Discord Application:
    *   Go to the Discord Developer Portal: https://discord.com/developers/applications
    *   Log in to the Discord website.
    *   Click on "New Application".
    *   Give the application a name and click "Create".
2. Configure the Bot:
    *   Navigate to the "Bot" tab on the left side of the screen.
    *   Make sure "Public Bot" is ticked if you want others to invite your bot.
	*	Generate your bot token by clicking on "Reset Token", Copy the token and save it securely.
        *   Do not share the bot token. Treat it like a password. If the token is leaked, regenerate it.
3. Enable Privileged Intents:
    *   Scroll down to the "Privileged Gateway Intents" section.
    *   Enable the necessary intents (e.g., "Server Members Intent" and "Message Content Intent").
   -->  Note: Enabling privileged intents for bots in over 100 guilds requires bot verification. You may need to contact Discord support to enable privileged intents for verified bots.
4. Generate Invite URL:
    *   Go to "OAuth2" tab and "OAuth2 URL Generator" section.
    *   Under "scopes", tick the "bot" checkbox.
    *   Tick the permissions required for your bot to function under ‚ÄúBot Permissions‚Äù.
		*	e.g. "Send Messages", "Send Messages in Threads", "Read Message History",  "Mention Everyone".
    *   Copy the generated URL under the "GENERATED URL" section at the bottom.
5. Invite the Bot:
    *   Paste the URL into your browser.
    *   Choose a server to invite the bot to.
    *   Click ‚ÄúAuthorize‚Äù.
   -->  Note: The person adding the bot needs "Manage Server" permissions.
6. Run the code below to start the bot with your bot token.
7. Write e.g. "/bu whats the weather in Tokyo?" to start a browser-use task and get a response inside the Discord channel.
"""

import os

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import SecretStr

from browser_use import BrowserConfig
from examples.integrations.discord.discord_api import DiscordBot

load_dotenv()

# load credentials from environment variables
bot_token = os.getenv('DISCORD_BOT_TOKEN')
if not bot_token:
	raise ValueError('Discord bot token not found in .env file.')

api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
	raise ValueError('GEMINI_API_KEY is not set')

llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=SecretStr(api_key))

bot = DiscordBot(
	llm=llm,  # required; instance of BaseChatModel
	prefix='$bu',  # optional; prefix of messages to trigger browser-use, defaults to "$bu"
	ack=True,  # optional; whether to acknowledge task receipt with a message, defaults to False
	browser_config=BrowserConfig(
		headless=False
	),  # optional; useful for changing headless mode or other browser configs, defaults to headless mode
)

bot.run(
	token=bot_token,  # required; Discord bot token
)



================================================
File: examples/integrations/slack/README.md
================================================
# Slack Integration

Steps to create and configure a Slack bot:

1. Create a Slack App:
    *   Go to the Slack API: https://api.slack.com/apps
    *   Click on "Create New App".
    *   Choose "From scratch" and give your app a name and select the workspace.
    *   Provide a name and description for your bot (these are required fields).
2. Configure the Bot:
    *   Navigate to the "OAuth & Permissions" tab on the left side of the screen.
    *   Under "Scopes", add the necessary bot token scopes (add these "chat:write", "channels:history", "im:history").
3. Enable Event Subscriptions:
    *   Navigate to the "Event Subscriptions" tab.
    *   Enable events and add the necessary bot events (add these "message.channels", "message.im").
    *   Add your request URL (you can use ngrok to expose your local server if needed). [See how to set up ngrok](#installing-and-starting-ngrok).
    *   **Note:** The URL provided by ngrok is ephemeral and will change each time ngrok is started. You will need to update the request URL in the bot's settings each time you restart ngrok. [See how to update the request URL](#updating-the-request-url-in-bots-settings).
4. Add the bot to your Slack workspace:
    *   Navigate to the "OAuth & Permissions" tab.
    *   Under "OAuth Tokens for Your Workspace", click on "Install App to Workspace".
    *   Follow the prompts to authorize the app and add it to your workspace.
5. Set up environment variables:
    *   Obtain the `SLACK_SIGNING_SECRET`:
        *   Go to the Slack API: https://api.slack.com/apps
        *   Select your app.
        *   Navigate to the "Basic Information" tab.
        *   Copy the "Signing Secret".
    *   Obtain the `SLACK_BOT_TOKEN`:
        *   Go to the Slack API: https://api.slack.com/apps
        *   Select your app.
        *   Navigate to the "OAuth & Permissions" tab.
        *   Copy the "Bot User OAuth Token".
    *   Create a `.env` file in the root directory of your project and add the following lines:
        ```env
        SLACK_SIGNING_SECRET=your-signing-secret
        SLACK_BOT_TOKEN=your-bot-token
        ```
6. Invite the bot to a channel:
    *   Use the `/invite @your-bot-name` command in the Slack channel where you want the bot to be active.
7. Run the code in `examples/slack_example.py` to start the bot with your bot token and signing secret.
8. Write e.g. "$bu whats the weather in Tokyo?" to start a browser-use task and get a response inside the Slack channel.

## Installing and Starting ngrok

To expose your local server to the internet, you can use ngrok. Follow these steps to install and start ngrok:

1. Download ngrok from the official website: https://ngrok.com/download
2. Create a free account and follow the offical steps to install ngrok.
3. Start ngrok by running the following command in your terminal:
    ```sh
    ngrok http 3000
    ```
    Replace `3000` with the port number your local server is running on.

## Updating the Request URL in Bot's Settings

If you need to update the request URL (e.g., when the ngrok URL changes), follow these steps:

1. Go to the Slack API: https://api.slack.com/apps
2. Select your app.
3. Navigate to the "Event Subscriptions" tab.
4. Update the "Request URL" field with the new ngrok URL. The URL should be something like: `https://<ngrok-id>.ngrok-free.app/slack/events`
5. Save the changes.

## Installing Required Packages

To run this example, you need to install the following packages:

- `fastapi`
- `uvicorn`
- `slack_sdk`

You can install these packages using pip:

```sh
pip install fastapi uvicorn slack_sdk


================================================
File: examples/integrations/slack/slack_api.py
================================================
import logging
from browser_use import BrowserConfig
from fastapi import FastAPI, Request, HTTPException, Depends
from dotenv import load_dotenv
from slack_sdk.web.async_client import AsyncWebClient
from slack_sdk.errors import SlackApiError
from slack_sdk.signature import SignatureVerifier
from browser_use.agent.service import Agent, Browser
from langchain_core.language_models.chat_models import BaseChatModel
from browser_use.logging_config import setup_logging

load_dotenv()

setup_logging()
logger = logging.getLogger('slack')

app = FastAPI()

class SlackBot:
    def __init__(self, llm: BaseChatModel, bot_token: str, signing_secret: str, ack: bool = False, browser_config: BrowserConfig = BrowserConfig(headless=True)):
        if not bot_token or not signing_secret:
            raise ValueError("Bot token and signing secret must be provided")
        
        self.llm = llm
        self.ack = ack
        self.browser_config = browser_config
        self.client = AsyncWebClient(token=bot_token)
        self.signature_verifier = SignatureVerifier(signing_secret)
        self.processed_events = set()
        logger.info("SlackBot initialized")

    async def handle_event(self, event, event_id):
        try:
            logger.info(f"Received event id: {event_id}")
            if not event_id:
                logger.warning("Event ID missing in event data")
                return

            if event_id in self.processed_events:
                logger.info(f"Event {event_id} already processed")
                return
            self.processed_events.add(event_id)

            if 'subtype' in event and event['subtype'] == 'bot_message':
                return

            text = event.get('text')
            user_id = event.get('user')
            if text and text.startswith('$bu '):
                task = text[len('$bu '):].strip()
                if self.ack:
                    try:
                        await self.send_message(event['channel'], f'<@{user_id}> Starting browser use task...', thread_ts=event.get('ts'))
                    except Exception as e:
                        logger.error(f"Error sending start message: {e}")

                try:
                    agent_message = await self.run_agent(task)
                    await self.send_message(event['channel'], f'<@{user_id}> {agent_message}', thread_ts=event.get('ts'))
                except Exception as e:
                    await self.send_message(event['channel'], f'Error during task execution: {str(e)}', thread_ts=event.get('ts'))
        except Exception as e:
            logger.error(f"Error in handle_event: {str(e)}")

    async def run_agent(self, task: str) -> str:
        try:
            browser = Browser(config=self.browser_config)
            agent = Agent(task=task, llm=self.llm, browser=browser)
            result = await agent.run()

            agent_message = None
            if result.is_done():
                agent_message = result.history[-1].result[0].extracted_content

            if agent_message is None:
                agent_message = 'Oops! Something went wrong while running Browser-Use.'

            return agent_message

        except Exception as e:
            logger.error(f"Error during task execution: {str(e)}")
            return f'Error during task execution: {str(e)}'

    async def send_message(self, channel, text, thread_ts=None):
        try:
            await self.client.chat_postMessage(channel=channel, text=text, thread_ts=thread_ts)
        except SlackApiError as e:
            logger.error(f"Error sending message: {e.response['error']}")

@app.post("/slack/events")
async def slack_events(request: Request, slack_bot: SlackBot = Depends()):
    try:
        if not slack_bot.signature_verifier.is_valid_request(await request.body(), dict(request.headers)):
            logger.warning("Request verification failed")
            raise HTTPException(status_code=400, detail="Request verification failed")

        event_data = await request.json()
        logger.info(f"Received event data: {event_data}")
        if 'challenge' in event_data:
            return {"challenge": event_data['challenge']}

        if 'event' in event_data:
            try:
                await slack_bot.handle_event(event_data.get('event'), event_data.get('event_id'))
            except Exception as e:
                logger.error(f"Error handling event: {str(e)}")

        return {}
    except Exception as e:
        logger.error(f"Error in slack_events: {str(e)}")
        raise HTTPException(status_code=500, detail="Internal Server Error")


================================================
File: examples/integrations/slack/slack_example.py
================================================
import os

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import SecretStr

from browser_use import BrowserConfig
from examples.integrations.slack.slack_api import SlackBot, app

load_dotenv()

# load credentials from environment variables
bot_token = os.getenv('SLACK_BOT_TOKEN')
if not bot_token:
	raise ValueError('Slack bot token not found in .env file.')

signing_secret = os.getenv('SLACK_SIGNING_SECRET')
if not signing_secret:
	raise ValueError('Slack signing secret not found in .env file.')

api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
	raise ValueError('GEMINI_API_KEY is not set')

llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=SecretStr(api_key))

slack_bot = SlackBot(
	llm=llm,  # required; instance of BaseChatModel
	bot_token=bot_token,  # required; Slack bot token
	signing_secret=signing_secret,  # required; Slack signing secret
	ack=True,  # optional; whether to acknowledge task receipt with a message, defaults to False
	browser_config=BrowserConfig(
		headless=True
	),  # optional; useful for changing headless mode or other browser configs, defaults to headless mode
)

app.dependency_overrides[SlackBot] = lambda: slack_bot

if __name__ == '__main__':
	import uvicorn

	uvicorn.run('integrations.slack.slack_api:app', host='0.0.0.0', port=3000)



================================================
File: examples/models/README.md
================================================
# Gemini
Detailed video on how to integrate browser-use with Gemini: https://www.youtube.com/watch?v=JluZiWBV_Tc



================================================
File: examples/models/azure_openai.py
================================================
"""
Simple try of the agent.

@dev You need to add AZURE_OPENAI_API_KEY and AZURE_OPENAI_ENDPOINT to your environment variables.
"""

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from langchain_openai import AzureChatOpenAI

from browser_use import Agent

# Retrieve Azure-specific environment variables
azure_openai_api_key = os.environ.get('AZURE_OPENAI_API_KEY')
azure_openai_endpoint = os.environ.get('AZURE_OPENAI_ENDPOINT')

# Initialize the Azure OpenAI client
llm = AzureChatOpenAI(
    model_name='gpt-4o', 
    openai_api_key=azure_openai_api_key,
    azure_endpoint=azure_openai_endpoint,  # Corrected to use azure_endpoint instead of openai_api_base
    deployment_name='gpt-4o',  # Use deployment_name for Azure models
    api_version='2024-08-01-preview'  # Explicitly set the API version here
)

agent = Agent(
    task='Go to amazon.com, search for laptop, sort by best rating, and give me the price of the first result',
    llm=llm,
)


async def main():
    await agent.run(max_steps=10)
    input('Press Enter to continue...')


asyncio.run(main())


================================================
File: examples/models/bedrock_claude.py
================================================
"""
Automated news analysis and sentiment scoring using Bedrock.

@dev Ensure AWS environment variables are set correctly for Bedrock access.
"""

import os
import sys

from langchain_aws import ChatBedrock

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import argparse
import asyncio

from browser_use import Agent
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.controller.service import Controller


def get_llm():
    return ChatBedrock(
        model_id="us.anthropic.claude-3-5-sonnet-20241022-v2:0",
        temperature=0.0,
        max_tokens=None,
    )


# Define the task for the agent
task = (
    "Visit cnn.com, navigate to the 'World News' section, and identify the latest headline. "
    "Open the first article and summarize its content in 3-4 sentences. "
    "Additionally, analyze the sentiment of the article (positive, neutral, or negative) "
    "and provide a confidence score for the sentiment. Present the result in a tabular format."
)

parser = argparse.ArgumentParser()
parser.add_argument('--query', type=str, help='The query for the agent to execute', default=task)
args = parser.parse_args()

llm = get_llm()

browser = Browser(
    config=BrowserConfig(
        # chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
    )
)

agent = Agent(
    task=args.query, llm=llm, controller=Controller(), browser=browser, validate_output=True,
)


async def main():
    await agent.run(max_steps=30)
    await browser.close()


asyncio.run(main())



================================================
File: examples/models/claude-3.7-sonnet.py
================================================
"""
Simple script that runs the task of opening amazon and searching.
@dev Ensure we have a `ANTHROPIC_API_KEY` variable in our `.env` file.
"""

import os
import sys
from dotenv import load_dotenv
from langchain_anthropic import ChatAnthropic

# Load environment variables from .env file
load_dotenv()

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from browser_use import Agent

llm = ChatAnthropic(model_name='claude-3-7-sonnet-20250219', temperature=0.0, timeout=30, stop=None)

agent = Agent(
	task='Go to amazon.com, search for laptop, sort by best rating, and give me the price of the first result',
	llm=llm,
)


async def main():
	await agent.run(max_steps=10)


asyncio.run(main())



================================================
File: examples/models/deepseek-r1.py
================================================
import asyncio
import os

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import SecretStr

from browser_use import Agent

# dotenv
load_dotenv()

api_key = os.getenv('DEEPSEEK_API_KEY', '')
if not api_key:
	raise ValueError('DEEPSEEK_API_KEY is not set')


async def run_search():
	agent = Agent(
		task=('go to amazon.com, search for laptop, sort by best rating, and give me the price of the first result'),
		llm=ChatOpenAI(
			base_url='https://api.deepseek.com/v1',
			model='deepseek-reasoner',
			api_key=SecretStr(api_key),
		),
		use_vision=False,
		max_failures=2,
		max_actions_per_step=1,
	)

	await agent.run()


if __name__ == '__main__':
	asyncio.run(run_search())



================================================
File: examples/models/deepseek.py
================================================
import asyncio
import os

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import SecretStr

from browser_use import Agent

# dotenv
load_dotenv()

api_key = os.getenv('DEEPSEEK_API_KEY', '')
if not api_key:
	raise ValueError('DEEPSEEK_API_KEY is not set')


async def run_search():
	agent = Agent(
		task=(
			'1. Go to https://www.reddit.com/r/LocalLLaMA '
			"2. Search for 'browser use' in the search bar"
			'3. Click on first result'
			'4. Return the first comment'
		),
		llm=ChatOpenAI(
			base_url='https://api.deepseek.com/v1',
			model='deepseek-chat',
			api_key=SecretStr(api_key),
		),
		use_vision=False,
	)

	await agent.run()


if __name__ == '__main__':
	asyncio.run(run_search())



================================================
File: examples/models/gemini.py
================================================
import asyncio
import os

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import SecretStr

from browser_use import Agent, BrowserConfig
from browser_use.browser.browser import Browser
from browser_use.browser.context import BrowserContextConfig

load_dotenv()
api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
	raise ValueError('GEMINI_API_KEY is not set')

llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=SecretStr(api_key))

browser = Browser(
	config=BrowserConfig(
		new_context_config=BrowserContextConfig(
			viewport_expansion=0,
		)
	)
)


async def run_search():
	agent = Agent(
		task='Go to amazon.com, search for laptop, sort by best rating, and give me the price of the first result',
		llm=llm,
		max_actions_per_step=4,
		browser=browser,
	)

	await agent.run(max_steps=25)


if __name__ == '__main__':
	asyncio.run(run_search())



================================================
File: examples/models/gpt-4o.py
================================================
"""
Simple try of the agent.

@dev You need to add OPENAI_API_KEY to your environment variables.
"""

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from langchain_openai import ChatOpenAI

from browser_use import Agent

llm = ChatOpenAI(model='gpt-4o')
agent = Agent(
	task='Go to amazon.com, search for laptop, sort by best rating, and give me the price of the first result',
	llm=llm,
)


async def main():
	await agent.run(max_steps=10)
	input('Press Enter to continue...')


asyncio.run(main())



================================================
File: examples/models/ollama.py
================================================
# import os

# Optional: Disable telemetry
# os.environ["ANONYMIZED_TELEMETRY"] = "false"

# Optional: Set the OLLAMA host to a remote server
# os.environ["OLLAMA_HOST"] = "http://x.x.x.x:11434"

import asyncio
from browser_use import Agent
from browser_use.agent.views import AgentHistoryList
from langchain_ollama import ChatOllama


async def run_search() -> AgentHistoryList:
    agent = Agent(
        task="Search for a 'browser use' post on the r/LocalLLaMA subreddit and open it.",
        llm=ChatOllama(
            model="qwen2.5:32b-instruct-q4_K_M",
            num_ctx=32000,
        ),
    )

    result = await agent.run()
    return result


async def main():
    result = await run_search()
    print("\n\n", result)


if __name__ == "__main__":
    asyncio.run(main())



================================================
File: examples/models/qwen.py
================================================
import asyncio
import os

from langchain_ollama import ChatOllama

from browser_use import Agent


async def run_search():
	agent = Agent(
		task=(
			'1. Go to https://www.reddit.com/r/LocalLLaMA'
			"2. Search for 'browser use' in the search bar"
			'3. Click search'
			'4. Call done'
		),
		llm=ChatOllama(
			# model='qwen2.5:32b-instruct-q4_K_M',
			# model='qwen2.5:14b',
			model='qwen2.5:latest',
			num_ctx=128000,
		),
		max_actions_per_step=1,
	)

	await agent.run()


if __name__ == '__main__':
	asyncio.run(run_search())



================================================
File: examples/notebook/agent_browsing.ipynb
================================================
# Jupyter notebook converted to Python script.


%pip install -U langgraph langchain_google_genai langchain_community langgraph-checkpoint-postgres  openai langchain_groq

%%capture --no-stderr
%pip install --upgrade --quiet  playwright > /dev/null
%pip install --upgrade --quiet  lxml browser-use langchain_openai

!playwright install

!pip install "anyio<4"

# This import is required only for jupyter notebooks, since they have their own eventloop
import nest_asyncio

nest_asyncio.apply()

from langchain_openai import ChatOpenAI
from google.colab import userdata


llm = ChatOpenAI(model="gpt-4o-mini", temperature=0, api_key=userdata.get('Open_api_key'))





llm.invoke("hi")
# Output:
#   AIMessage(content='Hello! How can I assist you today?', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 8, 'total_tokens': 18, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'stop', 'logprobs': None}, id='run-28a9088f-7539-412a-aa80-1663be40e74f-0', usage_metadata={'input_tokens': 8, 'output_tokens': 10, 'total_tokens': 18, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})

from browser_use import Agent, Browser
from browser_use import BrowserConfig
from langchain_openai import ChatOpenAI
import asyncio

# Basic configuration for the browser
config = BrowserConfig(
    headless=True,  # Run in headless mode
    # disable_security=True  # Uncomment if you want to disable security
)

# Initialize the browser with the specified configuration
browser = Browser(config=config)

async def main():
    # Initialize the agent with the task and language model
    agent = Agent(
        task="What is Langgraph",
        llm=llm,  # Replace with your LLM configuration
        browser=browser,
        generate_gif=False  # Disable GIF generation
    )

    # Run the agent and get results asynchronously
    result = await agent.run()

    # Process results token-wise
    for action in result.action_results():
      print(action.extracted_content,end="\r",flush=True)
      print("\n\n")
        # if action.is_done:
        #     print(action.extracted_content)

    # Close the browser after completion
    await browser.close()

# Run the asynchronous main function
asyncio.run(main())

# Output:
#   üîç  Searched for "What is Langgraph?" in Google

#   

#   

#   

#   

#   

#   üìÑ  Extracted page as markdown

#   : ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac879f622b3cb30dd7_cohere-logos-

#   idbbhgStc3%201.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdacfdbb3072f5258f66_hugging%20face.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdaceb29ce1602beb431_logo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac5f6f2a8c34e5575b_wblogo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdade49955197d2a8941_mosaic.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac5092327565075208_aws.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdacb28fe27c7784c797_goggle%20drive.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac325d487977a3398b_milvus.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac6348e83137a80c17_openai.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac0d888384ad7d31f3_redis.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdacf9d2dfca1d2a4c81_google%20cloud.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac76b6b8b79414144f_datastax%20logo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac15e6989ae752a9b5_notion%20logo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac485cb9900ddafda3_anthropic-

#   logo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdade49955197d2a894d_mongodb.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdacaeab9fdc6452063c_supabase.png)

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac879f622b3cb30dd7_cohere-logos-

#   idbbhgStc3%201.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdacfdbb3072f5258f66_hugging%20face.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdaceb29ce1602beb431_logo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac5f6f2a8c34e5575b_wblogo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdade49955197d2a8941_mosaic.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac5092327565075208_aws.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdacb28fe27c7784c797_goggle%20drive.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac325d487977a3398b_milvus.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac6348e83137a80c17_openai.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac0d888384ad7d31f3_redis.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdacf9d2dfca1d2a4c81_google%20cloud.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac76b6b8b79414144f_datastax%20logo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac15e6989ae752a9b5_notion%20logo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdac485cb9900ddafda3_anthropic-

#   logo.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdade49955197d2a894d_mongodb.png)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c8fdacaeab9fdc6452063c_supabase.png)

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667b080e4b3ca12dc5d5d439_Langgraph%20UI-2.webp)

#   

#   ## Controllable cognitive architecture for any task

#   

#   LangGraph's flexible framework supports diverse control flows ‚Äì single agent,

#   multi-agent, hierarchical, sequential ‚Äì and robustly handles realistic,

#   complex scenarios.  

#     

#   Ensure reliability with easy-to-add moderation and quality loops that prevent

#   agents from veering off course.  

#     

#   Use LangGraph Platform to templatize your cognitive architecture so that

#   tools, prompts, and models are easily configurable with LangGraph Platform

#   Assistants.

#   

#   [See the docs ](https://langchain-ai.github.io/langgraph/)

#   

#   ## Designed for human-agent collaboration

#   

#   With built-in statefulness, LangGraph agents seamlessly collaborate with

#   humans by writing drafts for review and awaiting approval before acting.

#   Easily inspect the agent‚Äôs actions and "time-travel" to roll back and take a

#   different action to correct course.

#   

#   [Read a conceptual guide ](https://langchain-

#   ai.github.io/langgraph/concepts/agentic_concepts/#human-in-the-loop)

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667c93d559216bb904fe85a8_gif7%20\(1\).gif)

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667c57f274b66a77e2a26b82_CleanShot2024-06-26at17.08.03-ezgif.com-

#   video-to-gif-converter.gif)

#   

#   ## First class streaming support for better UX design

#   

#   Bridge user expectations and agent capabilities with native token-by-token

#   streaming and streaming of intermediate steps, helpful for showing agent

#   reasoning and actions back to the user as they happen. Use LangGraph

#   Platform's API to deliver dynamic and interactive user experiences.

#   

#   [Learn more ](https://langchain-ai.github.io/langgraph/how-tos/streaming-

#   tokens/)

#   

#   ## Why choose LangGraph?

#   

#   ### Control, moderate, and guide your agent‚Äôs actions.

#   

#   Prevent agents from veering off course and ensure reliability with easy-to-add

#   moderation and quality loops. Add human-in-the-loop to steer and approve agent

#   actions.

#   

#   ### Expressive and customizable agent and multi-agent workflows.

#   

#   LangGraph‚Äôs low level abstractions offer the flexibility needed to create

#   sophisticated agents. Design diverse control flows ‚Äì single, multi-agent,

#   hierarchical, sequential ‚Äì all with one framework.

#   

#   ### Persisted context for long-term interactions.

#   

#   With its stateful design, LangGraph stores conversation histories and session

#   data to maintain context over time and ensure smooth handoffs in agentic

#   systems.

#   

#   ### First-class streaming support for better UX design.

#   

#   Bridge user expectations and agent capabilities with native token-by-token

#   streaming of intermediate steps, helpful for showing agent reasoning and

#   actions back to the user as they happen.

#   

#   ## LangGraph Platform:  

#   Deploy & develop agents at scale

#   

#   Craft agent-appropriate UXs using LangGraph Platform's APIs. Quickly deploy

#   and scale your agent with purpose-built infrastructure. Choose from multiple

#   deployment options.

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/67878de387cf10f90c7ad65f_LangGraph---

#   Memory-HQ.gif)

#   

#   ## Dynamic APIs for designing agent UXs.

#   

#   Craft personalized experiences with the long-term memory API to recall

#   information across conversation sessions. Expose, update, and rewind your

#   app's state for better user visibility, steering, and interaction. Kick off

#   long-running background jobs for research-style or multi-step work.

#   

#   [See the docs ](https://langchain-ai.github.io/langgraph/how-tos/streaming-

#   tokens/)

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/67879a0dd9100d8e643eb39e_LangGraph%20-%20Fault-

#   tolerant%20scalability.gif)

#   

#   ## Fault-tolerant scalability.

#   

#   Handle large workloads gracefully with horizontally-scaling servers, task

#   queues, and built-in persistence. Enhance resilience with intelligent caching

#   and automated retries.

#   

#   [Learn more in the blog ](https://langchain-ai.github.io/langgraph/how-

#   tos/streaming-tokens/)

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667c93d559216bb904fe85a8_gif7%20\(1\).gif)

#   

#   ## An end-to-end agent experience.

#   

#   Simplify prototyping, debugging, and sharing of agents in our visual LangGraph

#   Studio. Deploy your application with 1-click deploy with our SaaS offering or

#   within your own VPC. Then, monitor app performance with LangSmith.

#   

#   [Discover LangGraph Studio ](https://langchain-ai.github.io/langgraph/how-

#   tos/streaming-tokens/)

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/66db8c2317fe5b9ad2b84ea0_lcacademylogo.png)

#   

#   ## Introduction to LangGraph

#   

#   Learn the basics of LangGraph in this LangChain Academy Course. You'll learn

#   how to build agents that automate real-world tasks with LangGraph

#   orchestration.

#   

#   [Enroll for free](https://academy.langchain.com/courses/intro-to-

#   langgraph)[Book enterprise

#   training](https://airtable.com/appGjCAN6126Jm7K8/pagNAp7niHQzRH8zk/form)

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/6787ae429071ad3575902249_card%201%201.webp)![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/6787ae0bce5c99dd808545ce_card%202.webp)

#   

#   ## Deploy agents at scale, monitor carefully, iterate boldly

#   

#   Design agent-driven user experiences with LangGraph Platform's APIs. Quickly

#   deploy and scale your application with infrastructure built for agents. Choose

#   from multiple deployment options.

#   

#   ### Fault-tolerant scalability

#   

#   Handle large workloads gracefully with horizontally-scaling servers, task

#   queues, and built-in persistence. Enhance resilience with intelligent caching

#   and automated retries.

#   

#   ### Dynamic APIs for designing agent experience

#   

#   Craft personalized user experiences with APIs featuring long-term memory to

#   recall information across conversation sessions. Track, update, and rewind

#   your app's state for easy human steering and interaction. Kick off long-

#   running background jobs for research-style or multi-step work.

#   

#   ### Integrated developer experience

#   

#   Simplify prototyping, debugging, and sharing of agents in our visual LangGraph

#   Studio. Deploy your application with 1-click deploy with our SaaS offering or

#   within your own VPC. Then, monitor app performance with LangSmith.

#   

#   ### Trusted by companies taking agency in AI innovation:

#   

#   LangGraph helps teams of all sizes, across all industries, from ambitious

#   startups to established enterprises.

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c5308aea1371b447cc4af9_elastic-ar21.png)

#   

#   ‚ÄúLangChain is streets ahead with what they've put forward with LangGraph.

#   LangGraph sets the foundation for how we can build and scale AI workloads ‚Äî

#   from conversational agents, complex task automation, to custom LLM-backed

#   experiences that 'just work'. The next chapter in building complex production-

#   ready features with LLMs is agentic, and with LangGraph and LangSmith,

#   LangChain delivers an out-of-the-box solution to iterate quickly, debug

#   immediately, and scale effortlessly.‚Äù

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667b26a1b4576291d6a9335b_garrett%20spong%201.webp)

#   

#   Garrett Spong

#   

#   Principal SWE

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/6679de9dc4e7bee218d4b058_Norwegian-Cruise-

#   Line-Logo%202-2.webp)

#   

#   ‚ÄúLangGraph has been instrumental for our AI development. Its robust framework

#   for building stateful, multi-actor applications with LLMs has transformed how

#   we evaluate and optimize the performance of our AI guest-facing solutions.

#   LangGraph enables granular control over the agent's thought process, which has

#   empowered us to make data-driven and deliberate decisions to meet the diverse

#   needs of our guests.‚Äù

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667b265bed5f5a9d26d6b7d6_andres%20torres%201.webp)

#   

#   Andres Torres

#   

#   Sr. Solutions Architect

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667c6f809f0ebc7b1d72a99b_Replit.png)

#   

#   ‚ÄúIt's easy to build the prototype of a coding agent, but deceptively hard to

#   improve its reliability. Replit wants to give a coding agent to millions of

#   users ‚Äî reliability is our top priority, and will remain so for a long time.

#   LangGraph is giving us the control and ergonomics we need to build and ship

#   powerful coding agents.‚Äù

#   

#   ‚ÄúAs Ally advances its exploration of Generative AI,

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667c6fcaaa21bcf2fe006dbe_1690576438641%20\(1\)%201.webp)

#   

#   Michele Catasta

#   

#   President

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/6679e1baf7ea357d0763cde1_ally-

#   bank%201-2.png)

#   

#   ‚ÄúAs Ally advances its exploration of Generative AI, our tech labs is excited

#   by LangGraph, the new library from LangChain, which is central to our

#   experiments with multi-actor agentic workflows. We are committed to deepening

#   our partnership with LangChain.‚Äù

#   

#   ‚ÄúAs Ally advances its exploration of Generative AI,

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/6679e2d31352c6bd56c84280_ally.png)

#   

#   Sathish Muthukrishnan

#   

#   Chief Information, Data and Digital Officer

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/65c5308aea1371b447cc4af9_elastic-ar21.png)

#   

#   ‚ÄúLangChain is streets ahead with what they've put forward with LangGraph.

#   LangGraph sets the foundation for how we can build and scale AI workloads ‚Äî

#   from conversational agents, complex task automation, to custom LLM-backed

#   experiences that 'just work'. The next chapter in building complex production-

#   ready features with LLMs is agentic, and with LangGraph and LangSmith,

#   LangChain delivers an out-of-the-box solution to iterate quickly, debug

#   immediately, and scale effortlessly.‚Äù

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667b26a1b4576291d6a9335b_garrett%20spong%201.webp)

#   

#   Garrett Spong

#   

#   Principal SWE

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/6679de9dc4e7bee218d4b058_Norwegian-Cruise-

#   Line-Logo%202-2.webp)

#   

#   ‚ÄúLangGraph has been instrumental for our AI development. Its robust framework

#   for building stateful, multi-actor applications with LLMs has transformed how

#   we evaluate and optimize the performance of our AI guest-facing solutions.

#   LangGraph enables granular control over the agent's thought process, which has

#   empowered us to make data-driven and deliberate decisions to meet the diverse

#   needs of our guests.‚Äù

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667b265bed5f5a9d26d6b7d6_andres%20torres%201.webp)

#   

#   Andres Torres

#   

#   Sr. Solutions Architect

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667c6f809f0ebc7b1d72a99b_Replit.png)

#   

#   ‚ÄúIt's easy to build the prototype of a coding agent, but deceptively hard to

#   improve its reliability. Replit wants to give a coding agent to millions of

#   users ‚Äî reliability is our top priority, and will remain so for a long time.

#   LangGraph is giving us the control and ergonomics we need to build and ship

#   powerful coding agents.‚Äù

#   

#   ‚ÄúAs Ally advances its exploration of Generative AI,

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/667c6fcaaa21bcf2fe006dbe_1690576438641%20\(1\)%201.webp)

#   

#   Michele Catasta

#   

#   President

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/6679e1baf7ea357d0763cde1_ally-

#   bank%201-2.png)

#   

#   ‚ÄúAs Ally advances its exploration of Generative AI, our tech labs is excited

#   by LangGraph, the new library from LangChain, which is central to our

#   experiments with multi-actor agentic workflows. We are committed to deepening

#   our partnership with LangChain.‚Äù

#   

#   ‚ÄúAs Ally advances its exploration of Generative AI,

#   

#   ![](https://cdn.prod.website-

#   files.com/65b8cd72835ceeacd4449a53/6679e2d31352c6bd56c84280_ally.png)

#   

#   Sathish Muthukrishnan

#   

#   Chief Information, Data and Digital Officer

#   

#   ## LangGraph FAQs

#   

#   Do I need to use LangChain to use LangGraph? What‚Äôs the difference?

#   

#   No. LangGraph is an orchestration framework for complex agentic systems and is

#   more low-level and controllable than LangChain agents. LangChain provides a

#   standard interface to interact with models and other components, useful for

#   straight-forward chains and retrieval flows.

#   

#   How is LangGraph different from other agent frameworks?

#   

#   Other agentic frameworks can work for simple, generic tasks but fall short for

#   complex tasks bespoke to a company‚Äôs needs. LangGraph provides a more

#   expressive framework to handle companies‚Äô unique tasks without restricting

#   users to a single black-box cognitive architecture.

#   

#   Does LangGraph impact the performance of my app?

#   

#   LangGraph will not add any overhead to your code and is specifically designed

#   with streaming workflows in mind.

#   

#   Is LangGraph open source? Is it free?

#   

#   Yes. LangGraph is an MIT-licensed open-source library and is free to use.

#   

#   How are LangGraph and LangGraph Platform different?

#   

#   LangGraph is a stateful, orchestration framework that brings added control to

#   agent workflows. LangGraph Platform is a service for deploying and scaling

#   LangGraph applications, with an opinionated API for building agent UXs, plus

#   an integrated developer studio.

#   

#   LangGraph (open source)

#   

#   LangGraph Platform

#   

#   Features

#   

#   Stateful orchestration framework for agentic applications

#   

#   Scalable infrastructure for deploying LangGraph applications  

#   

#   Python and JavaScript

#   

#   Python and JavaScript  

#   

#   None

#   

#   Yes - useful for retrieving & updating state or long-term memory, or creating

#   a configurable assistant  

#   

#   Basic

#   

#   Dedicated mode for token-by-token messages  

#   

#   Community contributed

#   

#   Supported out-of-the-box  

#   

#   Self-managed

#   

#   Managed Postgres with efficient storage  

#   

#   Self-managed

#   

#   \- Cloud SaaS  

#   \- Free self-hosted  

#   \- Enterprise  

#   (BYOC or paid self-hosted)  

#   

#   Self-managed

#   

#   Auto-scaling of task queues and servers  

#   

#   Self-managed

#   

#   Automated retries  

#   

#   Simple threading

#   

#   Supports double-texting  

#   

#   None

#   

#   Cron scheduling  

#   

#   None

#   

#   Integrated with LangSmith for observability  

#   

#   LangGraph Studio for Desktop

#   

#   LangGraph Studio for Desktop & Cloud  

#   

#   What are my deployment options for LangGraph Platform?

#   

#   We currently have the following deployment options for LangGraph applications:  

#     

#   ‚Äç**Self-Hosted Lite** : A free (up to 1M nodes executed), limited version of

#   LangGraph Platform that you can run locally or in a self-hosted manner. This

#   version requires a LangSmith API key and logs all usage to LangSmith. Fewer

#   features are available than in paid plans.  

#   ‚Äç**Cloud SaaS:** Fully managed and hosted as part of LangSmith, with automatic

#   updates and zero maintenance.  

#   ‚Äç**Bring Your Own Cloud (BYOC):** Deploy LangGraph Platform within your VPC,

#   provisioned and run as a service. Keep data in your environment while

#   outsourcing the management of the service.  

#   **Self-Hosted Enterprise:** Deploy LangGraph entirely on your own

#   infrastructure.

#   

#   Is LangGraph Platform open source?

#   

#   No. LangGraph Platform is proprietary software.  

#     

#   There is a free, self-hosted version of LangGraph Platform with access to

#   basic features. The Cloud SaaS deployment option is free while in beta, but

#   will eventually be a paid service. We will always give ample notice before

#   charging for a service and reward our early adopters with preferential

#   pricing. The Bring Your Own Cloud (BYOC) and Self-Hosted Enterprise options

#   are also paid services. [Contact our sales team](/contact-sales) to learn

#   more.  

#     

#   For more information, see our [LangGraph Platform pricing page](/pricing-

#   langgraph-platform).

#   

#   ## Ready to start shipping reliable GenAI apps faster?

#   

#   Get started with LangChain, LangSmith, and LangGraph to enhance your LLM app

#   development, from prototype to production.

#   

#   [Contact Us](/contact-sales)[Sign Up](https://smith.langchain.com/)

#   

#   

#   

#   

#   

#   LangGraph is a flexible framework designed for building and scaling agentic applications. It allows for complex task handling and human-agent collaboration, supporting various control flows such as single-agent, multi-agent, hierarchical, and sequential. Key features include:

#   

#   - **Statefulness**: LangGraph agents maintain context over time, enabling smooth interactions.

#   - **Streaming Support**: It provides native token-by-token streaming for better user experience.

#   - **Moderation and Quality Loops**: These features ensure agents remain reliable and on course.

#   - **Dynamic APIs**: LangGraph offers APIs for crafting personalized user experiences and managing long-term memory.

#   - **Deployment Options**: It supports various deployment methods, including self-hosted and cloud solutions.

#   

#   

#   

#   


from browser_use import Agent, Browser
from playwright.async_api import BrowserContext
from browser_use import BrowserConfig
from langchain_openai import ChatOpenAI
# from browser_use import Agent
import asyncio
# Basic configuration
config = BrowserConfig(
    headless=True,

    # disable_security=True
)
# Reuse existing browser
browser = Browser(config=config)
# async def main():
agent = Agent(
      task="what is langchain",
      llm=llm,
      browser=browser,
      generate_gif = False # Browser instance will be reused
  )

result = await agent.run()
print(result)
# Manually close the browser
# asyncio.run(main())
await browser.close()

# Output:
#   AgentHistoryList(all_results=[ActionResult(is_done=False, extracted_content='üîç  Searched for "What is LangChain?" in Google', error=None, include_in_memory=True), ActionResult(is_done=False, extracted_content="üìÑ  Extracted page as markdown\n: # Filters and Topics\n\n[All](/search?sca_esv=4c6b8dc13bab3e46&q=What+is+LangChain%3F&source=lnms&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ0pQJegQIEhAB)\n\n[Images](/search?sca_esv=4c6b8dc13bab3e46&q=What+is+LangChain%3F&udm=2&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQtKgLegQIExAB)\n\n[Videos](/search?sca_esv=4c6b8dc13bab3e46&q=What+is+LangChain%3F&udm=7&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQtKgLegQIERAB)\n\n[Forums](/search?sca_esv=4c6b8dc13bab3e46&q=What+is+LangChain%3F&udm=18&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQs6gLegQIDxAB)\n\nWeb\n\n[Flights](/travel/flights?sca_esv=4c6b8dc13bab3e46&output=search&q=What+is+LangChain%3F&source=lnms&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&ved=1t:200715&ictx=111)\n\n[Finance](/finance?sca_esv=4c6b8dc13bab3e46&output=search&q=What+is+LangChain%3F&source=lnms&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ0pQJegQIDBAB)\n\nMore\n\n[Books](/search?sca_esv=4c6b8dc13bab3e46&q=What+is+LangChain%3F&udm=36&source=lnms&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ0pQJegQINxAB)\n\n[News](/search?sca_esv=4c6b8dc13bab3e46&q=What+is+LangChain%3F&tbm=nws&source=lnms&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ0pQJegQINhAB)\n\n[Shopping](/search?sca_esv=4c6b8dc13bab3e46&q=What+is+LangChain%3F&udm=28&fbs=AEQNm0Aa4sjWe7Rqy32pFwRj0UkWd8nbOJfsBGGB5IQQO6L3JyWp6w6_rxLPe8F8fpm5a55blYtaduielx1say4YCS0EIyvBb6VkaLhDZSOnSC94tp-\nJuFEDkvqUl_u6quB-Is11hrT6R6Y6jGPIGI0MqGRIdRYfHHK4Fm5f9UNWxYphEnPjChpmH-\nusjmkJN6Sk444PHRuqJvihdKgoqwGrUjYjqVvmxA&ved=1t:220175&ictx=111)\n\nTools\n\nAny time\n\nAny time\n\n[Past\nhour](/search?q=What+is+LangChain%3F&sca_esv=4c6b8dc13bab3e46&udm=14&source=lnt&tbs=qdr:h&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQpwV6BAgGEAc)\n\n[Past 24\nhours](/search?q=What+is+LangChain%3F&sca_esv=4c6b8dc13bab3e46&udm=14&source=lnt&tbs=qdr:d&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQpwV6BAgGEAg)\n\n[Past\nweek](/search?q=What+is+LangChain%3F&sca_esv=4c6b8dc13bab3e46&udm=14&source=lnt&tbs=qdr:w&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQpwV6BAgGEAk)\n\n[Past\nmonth](/search?q=What+is+LangChain%3F&sca_esv=4c6b8dc13bab3e46&udm=14&source=lnt&tbs=qdr:m&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQpwV6BAgGEAo)\n\n[Past\nyear](/search?q=What+is+LangChain%3F&sca_esv=4c6b8dc13bab3e46&udm=14&source=lnt&tbs=qdr:y&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQpwV6BAgGEAs)\n\nCustom range...\n\nCustom date range\n\nFromTo\n\nGo\n\nAll results\n\nAll results\n\n[Verbatim](/search?q=What+is+LangChain%3F&sca_esv=4c6b8dc13bab3e46&udm=14&source=lnt&tbs=li:1&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQpwV6BAgGEBM)\n\n[ Advanced Search\n](https://www.google.com/advanced_search?q=What+is+LangChain%3F&udm=14)\n\nCtrl+Shift+X to select\n\n![Google](https://fonts.gstatic.com/s/i/productlogos/googleg/v6/24px.svg)\n\n# Search settings\n\n[Search CustomizationOff](/history/optout?hl=en)\n\n[SafeSearchBlurring\non](/safesearch?prev=https://www.google.com/search?q%3DWhat%2Bis%2BLangChain?%26udm%3D14&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8JsIegQIChAH)\n\n[LanguageEnglish](/preferences?lang=1&hl=en&prev=https://www.google.com/search?q%3DWhat%2Bis%2BLangChain%253F%26sca_esv%3D4c6b8dc13bab3e46%26udm%3D14#languages)\n\n[Dark themeDevice\ndefault](/setprefs?hl=en&prev=https://www.google.com/search?q%3DWhat%2Bis%2BLangChain?%26udm%3D14%26pccc%3D1&sig=0_jfSkJcafppJyKAIkCWZpHFXzfrs%3D&cs=2&sa=X&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQqsEHegQIChAJ&ictx=1)\n\n[More\nsettings](/preferences?hl=en&prev=https://www.google.com/search?q%3DWhat%2Bis%2BLangChain%253F%26sca_esv%3D4c6b8dc13bab3e46%26udm%3D14)\n\nSend feedback\n\n[Help](https://support.google.com/websearch/?p=dsrp_search_hc&hl=en) ‚Ä¢\n[Privacy](https://policies.google.com/privacy?hl=en&fg=1) ‚Ä¢\n[Terms](https://policies.google.com/terms?hl=en&fg=1)\n\n# Search Results\n\n[  \nLangChain![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAAAM1BMVEUcPDwRNjYAMC8AKSd2goaZoaapr7T//v/g4ej49/+/xMn8+/8AFRNAVliSm6BUZWfLztSDUJcgAAAAu0lEQVR4AdWRR2JFIQhFLcgF+/5XG54lPZn/M+Qo1b0iPnzBf1LRU/oC+fjuGD/gY4NANUvRSwEUEta/DAXVKtchxSaKbH99gwWaC4Tzrw/NFkTzLvCTDxxiXxbcJlChhYOL85FlRhcTzJEnJ9SxQkuatQpVSkkE3ytBlwy8pdUPA2gCbWxupV0NGRhuVEEnGad483sUgynlScV6Xf/WKHcJhmh5SqEsJ+Hz+iz6Y31n8f0L5ON/J3tB3gAtjgsX/sngiAAAAABJRU5ErkJggg==)LangChainhttps://www.langchain.com](https://www.langchain.com/)\n\nLangChain\n\nhttps://www.langchain.com\n\n _LangChain_ is a composable framework to build with LLMs. LangGraph is the\norchestration framework for controllable agentic workflows. Run.\n\n\u200e[Docs](https://python.langchain.com/docs/introduction/) ¬∑\n\u200e[Products](https://www.langchain.com/langchain) ¬∑ \u200e[LangChain\nAcademy](https://academy.langchain.com/) ¬∑ \u200e[Join the LangChain\nCommunity](https://www.langchain.com/join-community)\n\n[  \nWhat is\nLangChain?![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAAAflBMVEUjLz4dKjohLT0NHzFQV2FKUlwAFywnM0IaKDgzPUpWXGUVJDbq6+3i4+X29/jLzc99gogAABubnqP///9yd393fIPY2twAAAAAAB8AACK1t7ujpqsADicAFitiaHGGi5GUmJ1pb3cAFCqJjpQ8RlIuOUZDS1errrEGHC/DxslAWrmhAAAA1UlEQVR4Ad2OhWGFMBBAI0iIlhzuTth/wHqLjPBf5FzQ64Hx10++H8H3GPX8IMQEE8JCGnFC0ImQSps3GVuIE5lCpii6EOQFhFAaHVV1ZvPm1rWSGbSqk3UvvQ70cKlkI8QFUGtMZ3QzxRz4uRPmMBvoFrAlVEVlB4jIpW1S8W6l/SLSjfF93xw6IZPDDCFBvi52Sd2zs+1haSB+OxHhzz2Is3KycKRomtp2mthYyTFr0YlbKwCtTJZp0LWbO4YuEBd09WHMYXlDCWPoAaMuCBzF6BX5AC2JD1u/hbEIAAAAAElFTkSuQmCC)Amazon\nWeb Serviceshttps://aws.amazon.com ‚Ä∫ ... ‚Ä∫ Generative\nAI](https://aws.amazon.com/what-is/langchain/)\n\nAmazon Web Services\n\nhttps://aws.amazon.com ‚Ä∫ ... ‚Ä∫ Generative AI\n\nLangChain _provides AI developers with tools to connect language models with\nexternal data sources_. It is open-source and supported by an active\ncommunity.\n\n[  \nWhat Is LangChain and How to Use It: A\nGuide![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAAANlBMVEVHcEwAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkQAIkT2h/2dAAAAEnRSTlMASA176IbPqP9pXzX1LR7fI79igdKzAAAA60lEQVR4Ab2SR2IDMQgAR7BoEYuK///YVHf7msxJojf+g1J4i+hm1Erd3/hsvhVEaCH7wQPh2YAeB4wM7ik+F+uEuacC7c5XMocUCWCYVyHtpjQPSoW278GYFeHGNllCn1W1zjVcaSfOHG7UYBqATSzvlOEFodXzj+V39aivbuzKDz3I4FRuyvCbspCxXG9hDx9xH7Z4nJXdjbRzQdKwxLzftaI+1qzai7FcmdtdRY06B20vsGalud7Gt+WQ6jZgmVdZucnT4DU901NZ08vryo6IA1p6vCx7Wlmr2M/WX8/Ef9hUeEMP1ej8OZ+MHAj3YNWlQgAAAABJRU5ErkJggg==)TechTargethttps://www.techtarget.com\n‚Ä∫ definition ‚Ä∫\nLangChain](https://www.techtarget.com/searchenterpriseai/definition/LangChain)\n\nTechTarget\n\nhttps://www.techtarget.com ‚Ä∫ definition ‚Ä∫ LangChain\n\n _LangChain is an open source framework_ that enables software developers\nworking with artificial intelligence (AI) and its machine learning subset to\ncombine ...\n\n[  \nIntroduction | ü¶úÔ∏è LangChain![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAAAPFBMVEUdPT1OZGZzg4fT194cPDwUNzf///8dPT0ePj75+P/y8vrAxcw6UlQGMjGSnqMsSEnk5u2Cj5OrtbpgdHaG8/c5AAAACXRSTlPv////////b24kxPwmAAAA1klEQVQokcWS2Y7DIAxFsR3TYhaz/P+/DkvSppFSaR5Gcx+Q4HjjgnludzJPY25hx1/YX0P+0Bkya4CTgm58QFYk+yEqyguyVmfJZ3coZysp8MpM4nKIfV3ypdROZyYD9eCiwe8MPYFYAu4w4kjJLS7qoQdv4gTjgMX2M0mRlSaDFqp1tiw4q5FybCJAhFpH+ITcaPXaQiTpDXGWXz37tGMjtaWSrEesMtvsJoQ6JvKeJI9Lzjr1uCeHdHVoerB7q9DwpAZvb69v8nqW//wmv4bGPO7x4weTRBHU/VcIdwAAAABJRU5ErkJggg==)LangChainhttps://python.langchain.com ‚Ä∫ docs ‚Ä∫ introduction](https://python.langchain.com/docs/introduction/)\n\nLangChain\n\nhttps://python.langchain.com ‚Ä∫ docs ‚Ä∫ introduction\n\n _LangChain_ is a framework for developing applications powered by large\nlanguage models (LLMs). LangChain simplifies every stage of the LLM\napplication lifecycle.\n\n\u200e[Introduction](https://python.langchain.com/v0.1/docs/get_started/introduction/)\n¬∑\n\u200e[Langchain.agents...](https://api.python.langchain.com/en/latest/agents/langchain.agents.tool_calling_agent.base.create_tool_calling_agent.html)\n¬∑ \u200e[LangChain v0.3](https://python.langchain.com/docs/versions/v0_3/) ¬∑\n\u200e[Langchain_core.tools.](https://api.python.langchain.com/en/latest/tools/langchain_core.tools.tool.html)\n\n[  \nWhat Is\nLangChain?![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAAAQlBMVEVHcEwAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAABz07T7AAAAFnRSTlMABWTNoAuOPcGA32tTRXW1FyYt7PT+Xc8YuAAAANZJREFUeAHNx8t1xSAMBcArQCD+AkP/rcYhXiTHKeDNbvC5yFjH5K0hvAWJKZcUJeCtSpFmbJGKN45JmHuKjBdV8AhhMFTxB4Xo5oj2umwc08VAeEBzl0uouqPQnZ4V34ZL0sZlQEw3Jpg1miQ3gLF6YMzNNT4KrwAOfQ1Yj5t4+P3oHC1u3mJNALoVIZsjV9I9AcyFVAB4AVgfDIgDUBKaLSGnCs7SD2mMmlootoGjSDcA+72O7RQwXSQyQGMqbjrHMZV+RviFH/hP20cj/Gd6ET/xwb4A8CUMDSJ3MyIAAAAASUVORK5CYII=)IBMhttps://www.ibm.com\n‚Ä∫ think ‚Ä∫ topics ‚Ä∫ langchain](https://www.ibm.com/think/topics/langchain)\n\nIBM\n\nhttps://www.ibm.com ‚Ä∫ think ‚Ä∫ topics ‚Ä∫ langchain\n\nLangChain is essentially _a library of abstractions for Python and Javascript_\n, representing common steps and concepts necessary to work with language\nmodels.\n\n[  \nWhat is\nLangChain?![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAQCAYAAAAf8/9hAAAAcElEQVR4AWP4//8/RZh6BgCZAkDsAMUNWDFCXgDFACCV8J/B+D8pGKwHRAKRAUyQDEMMQAYEUGBAAsiABpwKHjz4/9/BAZ8BDXgNgIMNGyg04MABkg1AeCEgAK8XKA5EiqORooSELykXEJuUBz43AgAIA1ZhBoG9vwAAAABJRU5ErkJggg==)YouTube\n¬∑ IBM Technology287.6K+ views ¬∑ 10 months\nago](https://www.youtube.com/watch?v=1bUy-1hGZpI)\n\nYouTube ¬∑ IBM Technology\n\n287.6K+ views ¬∑ 10 months ago\n\nLang chain is _an open-source orchestration framework_ for the development of\napplications that use large language models.\n\n[  \nWhat is Langchain and why should I care as a\ndeveloper?![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAAAQlBMVEVHcEwAAAAAAAAAAAAAAAAAAABxcXGkpKSUlJQeHh5/f3/Q0ND////e3t6rq6taWlrHx8e0tLQsLCw+Pj7u7u62trYTUwO8AAAABnRSTlMAS8D5/5dwkjMFAAAA1klEQVR4AX3TRQLEIAwFUNoGhypz/6vOJ9SFrAIPFyFE03b0iK5tBELSR0j0o89oRPuNrei+sRNUiYJKa20slXAoqBOSDyG4klqkns6oURNLapD2F+x7VA2cjvqOkwWOZfq+oPLTjiN0zh3nibHHGnYcgJpo8cTosIQdZ4pQJIoRpf6MjncTiRFL8H1/oE3YjTEFF972gZR3k2jH/oILL2kfNl2QsBu7Yl7eeEGF8oq8vLSi56NLA+d88D/ofmW5K5vqy5Upj56VqD+T6gOrPs3qo659hz8m8RNl7wTa8QAAAABJRU5ErkJggg==)Medium\n¬∑ Logan Kilpatrick370+ likes ¬∑ 1 year ago](https://medium.com/around-the-\nprompt/what-is-langchain-and-why-should-i-care-as-a-developer-b2d952c42b28)\n\nMedium ¬∑ Logan Kilpatrick\n\n370+ likes ¬∑ 1 year ago\n\n _Langchain_ makes creating agents using large language models simple through\ntheir agents API. Developers can use OpenAI functions or other means ...\n\n[  \nLangChain![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAnklEQVR4AeTNIQiDQABG4b+u17X1aF6PK3YEO9iMJqPVau82y4FgMezS0oVLhqsHtrcqeqzDXv3CEz/6L4yTtZM3dnHmPTtjzXZAXKYVo4agkU2GI2Lloc6JDez1+flswMu1EQZ3xlE7lK8eKDkjtwE+crBMV+wesKmCiisGGepZIfQJpMj9SNb2MYWrChjVkULuCyCfRvsdmBieyQQAsoDk/9ryhFMAAAAASUVORK5CYII=)Wikipediahttps://en.wikipedia.org\n‚Ä∫ wiki ‚Ä∫ LangChain](https://en.wikipedia.org/wiki/LangChain)\n\nWikipedia\n\nhttps://en.wikipedia.org ‚Ä∫ wiki ‚Ä∫ LangChain\n\nLangChain is a software framework that helps facilitate the integration of\nlarge language models (LLMs) into applications.\n\n\u200e[History](https://en.wikipedia.org/wiki/LangChain#History) ¬∑\n\u200e[Capabilities](https://en.wikipedia.org/wiki/LangChain#Capabilities) ¬∑\n\u200e[LangChain tools](https://en.wikipedia.org/wiki/LangChain#LangChain_tools)\n\n[  \nWhat Is LangChain? A Complete Comprehensive\nOverview![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAMAAABF0y+mAAAAMFBMVEX///////////8AAADNzc2/v7+np6eOjo7x8fGenp4mJibe3t5BQUFdXV1oaGh9fX0JTbfNAAAAAnRSTlP8WKsquk8AAAB7SURBVCiR1ZNLDoAgDAWhRSgf8f63lT8GhZULndWjk7ShAcYZTGCcTV2wCxfs76TdMhQLVA5VaiwIAFFzl4eMOCRCJzNdpiawR+mHmRcJrnS1TxKUSaTSTWYE6ia9ipggZUrKoxyvEgbVmbotQWSoZ/vCbr8ll4969R1OiO0IjOTl5agAAAAASUVORK5CYII=)DataStaxhttps://www.datastax.com\n‚Ä∫ guides ‚Ä∫ what-is-langchain](https://www.datastax.com/guides/what-is-\nlangchain)\n\nDataStax\n\nhttps://www.datastax.com ‚Ä∫ guides ‚Ä∫ what-is-langchain\n\nNov 9, 2023 ‚Äî LangChain is _a Python framework designed to streamline AI\napplication development_ , focusing on real-time data processing and\nintegration with ...\n\n[  \nWhat Is\nLangChain?![](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAYAAAByDd+UAAABp0lEQVR4AWJwL/ChKx4aFt5K9AFUW5cADYVRGIZxqxRcOu7uVnC33hPuW0+QiHgl4m6ZXnBouP7cDz1czj/X8M53nu26N7I8SICLwmSN0uFFQbKg4TW8h89YBMQwFSINnzUHBHZsKIauCmLFcUHugZGg6RjuK4YuRb729swoEL+SG0rW2TjC43+Y5lEUaG9EnvZ2ngWZf5aNL5/npr7Qe/yI295Af/Xn8RreoxgpSy+IL181xYnbseA32uumeybel4V/pMLQLg+SX4vhL6sugva86InQtVKJDCUQ6S6MBZVBEUpqQJaGB28HpSgDCmOS/MNEAFwUBDZpDMZtPAj/RAKiUQLqXmxYbzzGh+Gyf+mCrY/BJskAikZwgBFbbRYGtatBfhcwLgxnwHYORCUWAMtkYKIavF3027IAuMuAiexG87boIoBGTjXlJs1WhnNhi+TCUA5DdCvVUAz3pXMVInqmTiTN1P4rca6IHjcN7HbwB0TKPzpjMIuA9HT15zICKMEsAgLD7L8gKXGmehBDLQSOGnzGxwYDXBbWCd9Np1KZc1+XOhX4DttSLI3wbnoRAAAAAElFTkSuQmCC)Google\nCloudhttps://cloud.google.com ‚Ä∫ use-cases ‚Ä∫\nlangchain](https://cloud.google.com/use-cases/langchain)\n\nGoogle Cloud\n\nhttps://cloud.google.com ‚Ä∫ use-cases ‚Ä∫ langchain\n\n _LangChain_ is a programming language platform that lets developers construct\nand connect models to access, transform, and share data seamlessly.\n\n\u200e[Langchain And Ai](https://cloud.google.com/use-\ncases/langchain#:~:text=LangChain%20and%20AI) ¬∑ \u200e[How Does Langchain\nWork?](https://cloud.google.com/use-\ncases/langchain#:~:text=How%20does%20LangChain%20work%3F) ¬∑ \u200e[Key Features Of\nLangchain](https://cloud.google.com/use-\ncases/langchain#:~:text=Key%20features%20of%20LangChain)\n\n# Page Navigation\n\n| 1|\n[2](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=10&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAE)|\n[3](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=20&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAG)|\n[4](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=30&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAI)|\n[5](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=40&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAK)|\n[6](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=50&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAM)|\n[7](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=60&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAO)|\n[8](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=70&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAQ)|\n[9](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=80&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAS)|\n[10](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=90&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8tMDegQICBAU)|\n[Next](/search?q=What+is+LangChain?&sca_esv=4c6b8dc13bab3e46&udm=14&ei=e8iJZ425Mabg0PEP6LmQGQ&start=10&sa=N&sstk=ATObxK4t7c6xZe8J3zQzlUfrNV-\nBchujCI0GxH83wgy_vu9jEqYrHuTxd0wVBzubCa-bn_k1uK_Zn1BBIfr2yh6eyUzMdvUxFJ-\nmCw&ved=2ahUKEwjN4oy74vuKAxUmMDQIHegcJAMQ8NMDegQICBAW)  \n---|---|---|---|---|---|---|---|---|---|---|---  \n  \n# Footer Links\n\nWasco County, Oregon \\- From your IP address\n\n\\-\n\nUpdate location\n\nCan't update your locationLearn more\n\nUpdating location...\n\n[Help](https://support.google.com/websearch/?p=ws_results_help&hl=en&fg=1)Send\nfeedback[Privacy](https://policies.google.com/privacy?hl=en&fg=1)[Terms](https://policies.google.com/terms?hl=en&fg=1)\n\n\n", error=None, include_in_memory=False), ActionResult(is_done=True, extracted_content='LangChain is a composable framework designed for building applications with large language models (LLMs). It simplifies the integration of language models with external data sources and is open-source, supported by an active community. LangChain provides tools for developers to streamline the application lifecycle of LLMs.', error=None, include_in_memory=False)], all_model_outputs=[{'search_google': {'query': 'What is LangChain?'}}, {'extract_content': {'include_links': True}}, {'done': {'text': 'LangChain is a composable framework designed for building applications with large language models (LLMs). It simplifies the integration of language models with external data sources and is open-source, supported by an active community. LangChain provides tools for developers to streamline the application lifecycle of LLMs.'}}])


# display(result.action_results())
for action in result.action_results():
  if action.is_done:
    print(action.extracted_content)

# Output:
#   LangChain is a composable framework designed for building applications with large language models (LLMs). It simplifies the integration of language models with external data sources and is open-source, supported by an active community. LangChain provides tools for developers to streamline the application lifecycle of LLMs.




================================================
File: examples/ui/README.md
================================================
# **User Interfaces of Browser-Use**

| **File Name**          | **User Interface** | **Description**                           | **Example Usage**                         |
|------------------------|-------------------|-------------------------------------------|-------------------------------------------|
| `command_line.py`      | **Terminal**      | Parses arguments for command-line execution. | `python command_line.py`                  |
| `gradio_demo.py`       | **Gradio**        | Provides a Gradio-based interactive UI.  | `python gradio_demo.py`                   |
| `streamlit_demo.py`    | **Streamlit**     | Runs a Streamlit-based web interface.    | `python -m streamlit run streamlit_demo.py` |


================================================
File: examples/ui/command_line.py
================================================
"""
To Use It:

Example 1: Using OpenAI (default), with default task: 'go to reddit and search for posts about browser-use'
python command_line.py

Example 2: Using OpenAI with a Custom Query
python command_line.py --query "go to google and search for browser-use"

Example 3: Using Anthropic's Claude Model with a Custom Query
python command_line.py --query "find latest Python tutorials on Medium" --provider anthropic

"""
import os
import sys
import argparse
import asyncio

# Ensure local repository (browser_use) is accessible
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv

from browser_use import Agent
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.controller.service import Controller


load_dotenv()

def get_llm(provider: str):
	if provider == 'anthropic':
		from langchain_anthropic import ChatAnthropic
		api_key = os.getenv("ANTHROPIC_API_KEY")
		if not api_key:
			raise ValueError("Error: ANTHROPIC_API_KEY is not set. Please provide a valid API key.")
        
		return ChatAnthropic(
			model_name='claude-3-5-sonnet-20240620', timeout=25, stop=None, temperature=0.0
		)
	elif provider == 'openai':
		from langchain_openai import ChatOpenAI
		api_key = os.getenv("OPENAI_API_KEY")
		if not api_key:
			raise ValueError("Error: OPENAI_API_KEY is not set. Please provide a valid API key.")
        
		return ChatOpenAI(model='gpt-4o', temperature=0.0)

	else:
		raise ValueError(f'Unsupported provider: {provider}')

def parse_arguments():
    """Parse command-line arguments."""
    parser = argparse.ArgumentParser(description="Automate browser tasks using an LLM agent.")
    parser.add_argument(
        '--query',
        type=str,
        help='The query to process',
        default='go to reddit and search for posts about browser-use'
    )
    parser.add_argument(
        '--provider',
        type=str,
        choices=['openai', 'anthropic'],
        default='openai',
        help='The model provider to use (default: openai)',
    )
    return parser.parse_args()

def initialize_agent(query: str, provider: str):
    """Initialize the browser agent with the given query and provider."""
    llm = get_llm(provider)
    controller = Controller()
    browser = Browser(config=BrowserConfig())

    return Agent(
        task=query,
        llm=llm,
        controller=controller,
        browser=browser,
        use_vision=True,
        max_actions_per_step=1,
    ), browser

async def main():
    """Main async function to run the agent."""
    args = parse_arguments()
    agent, browser = initialize_agent(args.query, args.provider)

    await agent.run(max_steps=25)
    
    input('Press Enter to close the browser...')
    await browser.close()


if __name__ == "__main__":
    asyncio.run(main())


================================================
File: examples/ui/gradio_demo.py
================================================
import os
import asyncio
from dataclasses import dataclass
from typing import List, Optional

# Third-party imports
import gradio as gr
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from rich.console import Console
from rich.panel import Panel
from rich.text import Text

# Local module imports
from browser_use import Agent

load_dotenv()


@dataclass
class ActionResult:
	is_done: bool
	extracted_content: Optional[str]
	error: Optional[str]
	include_in_memory: bool


@dataclass
class AgentHistoryList:
	all_results: List[ActionResult]
	all_model_outputs: List[dict]


def parse_agent_history(history_str: str) -> None:
	console = Console()

	# Split the content into sections based on ActionResult entries
	sections = history_str.split('ActionResult(')

	for i, section in enumerate(sections[1:], 1):  # Skip first empty section
		# Extract relevant information
		content = ''
		if 'extracted_content=' in section:
			content = section.split('extracted_content=')[1].split(',')[0].strip("'")

		if content:
			header = Text(f'Step {i}', style='bold blue')
			panel = Panel(content, title=header, border_style='blue')
			console.print(panel)
			console.print()


async def run_browser_task(
	task: str,
	api_key: str,
	model: str = 'gpt-4o',
	headless: bool = True,
) -> str:
	if not api_key.strip():
		return 'Please provide an API key'

	os.environ['OPENAI_API_KEY'] = api_key

	try:
		agent = Agent(
			task=task,
			llm=ChatOpenAI(model='gpt-4o'),
		)
		result = await agent.run()
		#  TODO: The result cloud be parsed better
		return result
	except Exception as e:
		return f'Error: {str(e)}'


def create_ui():
	with gr.Blocks(title='Browser Use GUI') as interface:
		gr.Markdown('# Browser Use Task Automation')

		with gr.Row():
			with gr.Column():
				api_key = gr.Textbox(label='OpenAI API Key', placeholder='sk-...', type='password')
				task = gr.Textbox(
					label='Task Description',
					placeholder='E.g., Find flights from New York to London for next week',
					lines=3,
				)
				model = gr.Dropdown(
					choices=['gpt-4', 'gpt-3.5-turbo'], label='Model', value='gpt-4'
				)
				headless = gr.Checkbox(label='Run Headless', value=True)
				submit_btn = gr.Button('Run Task')

			with gr.Column():
				output = gr.Textbox(label='Output', lines=10, interactive=False)

		submit_btn.click(
			fn=lambda *args: asyncio.run(run_browser_task(*args)),
			inputs=[task, api_key, model, headless],
			outputs=output,
		)

	return interface


if __name__ == '__main__':
	demo = create_ui()
	demo.launch()


================================================
File: examples/ui/streamlit_demo.py
================================================
"""
To use it, you'll need to install streamlit, and run with:

python -m streamlit run streamlit_demo.py

"""

import os
import sys
import asyncio
import streamlit as st
from dotenv import load_dotenv

# Ensure local repository (browser_use) is accessible
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from browser_use import Agent
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.controller.service import Controller

# Load environment variables
load_dotenv()

# Function to get the LLM based on provider
def get_llm(provider: str):
    if provider == 'anthropic':
        from langchain_anthropic import ChatAnthropic
        api_key = os.getenv("ANTHROPIC_API_KEY")
        if not api_key:
            st.error("Error: ANTHROPIC_API_KEY is not set. Please provide a valid API key.")
            st.stop()
        
        return ChatAnthropic(
            model_name='claude-3-5-sonnet-20240620', timeout=25, stop=None, temperature=0.0
        )
    elif provider == 'openai':
        from langchain_openai import ChatOpenAI
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            st.error("Error: OPENAI_API_KEY is not set. Please provide a valid API key.")
            st.stop()
        
        return ChatOpenAI(model='gpt-4o', temperature=0.0)
    else:
        st.error(f'Unsupported provider: {provider}')
        st.stop()

# Function to initialize the agent
def initialize_agent(query: str, provider: str):
    llm = get_llm(provider)
    controller = Controller()
    browser = Browser(config=BrowserConfig())

    return Agent(
        task=query,
        llm=llm,
        controller=controller,
        browser=browser,
        use_vision=True,
        max_actions_per_step=1,
    ), browser

# Streamlit UI
st.title("Automated Browser Agent with LLMs ü§ñ")

query = st.text_input("Enter your query:", "go to reddit and search for posts about browser-use")
provider = st.radio("Select LLM Provider:", ["openai", "anthropic"], index=0)

if st.button("Run Agent"):
    st.write("Initializing agent...")
    agent, browser = initialize_agent(query, provider)

    async def run_agent():
        with st.spinner("Running automation..."):
            await agent.run(max_steps=25)
        st.success("Task completed! üéâ")

    asyncio.run(run_agent())

    st.button("Close Browser", on_click=lambda: asyncio.run(browser.close()))



================================================
File: examples/use-cases/README.md
================================================
# Use Cases of Browser-Use

| File Name | Description |
|-----------|------------|
| `captcha.py` | Automates CAPTCHA solving on a demo website. |
| `check_appointment.py` | Checks for available visa appointment slots on the Greece MFA website. |
| `find_and_apply_to_jobs.py` | Searches for job listings, evaluates relevance based on a CV, and applies automatically. |
| `online_coding_agent.py` | Implements a multi-agent system for online code editors, with separate agents for coding and execution. |
| `post-twitter.py` | Provides a template for automated posting on X (Twitter), including new tweets, tagging, and replies. |
| `scrolling_page.py` | Automates webpage scrolling with various scrolling actions and text search functionality. |
| `twitter_post_using_cookies.py` | Automates posting on X (Twitter) using stored authentication cookies. |
| `web_voyager_agent.py` | A general-purpose web navigation agent for tasks like flight booking and course searching. |






================================================
File: examples/use-cases/captcha.py
================================================
"""
Goal: Automates CAPTCHA solving on a demo website.


Simple try of the agent.
@dev You need to add OPENAI_API_KEY to your environment variables.
NOTE: captchas are hard. For this example it works. But e.g. for iframes it does not.
for this example it helps to zoom in.
"""

import os
import sys

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio
from langchain_openai import ChatOpenAI
from browser_use import Agent
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
if not os.getenv('OPENAI_API_KEY'):
    raise ValueError('OPENAI_API_KEY is not set. Please add it to your environment variables.')

async def main():
    llm = ChatOpenAI(model='gpt-4o')
    agent = Agent(
		task='go to https://captcha.com/demos/features/captcha-demo.aspx and solve the captcha',
		llm=llm,
	)
    await agent.run()
    input('Press Enter to exit')

if __name__ == "__main__":
    asyncio.run(main())


================================================
File: examples/use-cases/check_appointment.py
================================================
# Goal: Checks for available visa appointment slots on the Greece MFA website.

import asyncio
import os

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, SecretStr

from browser_use.agent.service import Agent
from browser_use.controller.service import Controller

# Load environment variables
load_dotenv()
if not os.getenv('OPENAI_API_KEY'):
    raise ValueError('OPENAI_API_KEY is not set. Please add it to your environment variables.')

controller = Controller()


class WebpageInfo(BaseModel):
	"""Model for webpage link."""
	link: str = 'https://appointment.mfa.gr/en/reservations/aero/ireland-grcon-dub/'


@controller.action('Go to the webpage', param_model=WebpageInfo)
def go_to_webpage(webpage_info: WebpageInfo):
	"""Returns the webpage link."""
	return webpage_info.link


async def main():
	"""Main function to execute the agent task."""
	task = (
		'Go to the Greece MFA webpage via the link I provided you.'
		'Check the visa appointment dates. If there is no available date in this month, check the next month.'
		'If there is no available date in both months, tell me there is no available date.'
	)

	model = ChatOpenAI(model='gpt-4o-mini', api_key=SecretStr(os.getenv('OPENAI_API_KEY', '')))
	agent = Agent(task, model, controller=controller, use_vision=True)

	await agent.run()


if __name__ == "__main__":
	asyncio.run(main())



================================================
File: examples/use-cases/find_and_apply_to_jobs.py
================================================
"""
Goal: Searches for job listings, evaluates relevance based on a CV, and applies 

@dev You need to add OPENAI_API_KEY to your environment variables.
Also you have to install PyPDF2 to read pdf files: pip install PyPDF2
"""

import csv
import os
import sys
from pathlib import Path
import logging
from typing import List, Optional
import asyncio

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from PyPDF2 import PdfReader
from langchain_openai import AzureChatOpenAI, ChatOpenAI
from pydantic import BaseModel, SecretStr

from browser_use import ActionResult, Agent, Controller
from browser_use.browser.context import BrowserContext
from browser_use.browser.browser import Browser, BrowserConfig

# Validate required environment variables
load_dotenv()
required_env_vars = ["AZURE_OPENAI_KEY", "AZURE_OPENAI_ENDPOINT"]
for var in required_env_vars:
    if not os.getenv(var):
        raise ValueError(f"{var} is not set. Please add it to your environment variables.")

logger = logging.getLogger(__name__)
# full screen mode
controller = Controller()

# NOTE: This is the path to your cv file
CV = Path.cwd() / 'cv_04_24.pdf'

if not CV.exists():
	raise FileNotFoundError(f'You need to set the path to your cv file in the CV variable. CV file not found at {CV}')


class Job(BaseModel):
	title: str
	link: str
	company: str
	fit_score: float
	location: Optional[str] = None
	salary: Optional[str] = None


@controller.action('Save jobs to file - with a score how well it fits to my profile', param_model=Job)
def save_jobs(job: Job):
	with open('jobs.csv', 'a', newline='') as f:
		writer = csv.writer(f)
		writer.writerow([job.title, job.company, job.link, job.salary, job.location])

	return 'Saved job to file'


@controller.action('Read jobs from file')
def read_jobs():
	with open('jobs.csv', 'r') as f:
		return f.read()


@controller.action('Read my cv for context to fill forms')
def read_cv():
	pdf = PdfReader(CV)
	text = ''
	for page in pdf.pages:
		text += page.extract_text() or ''
	logger.info(f'Read cv with {len(text)} characters')
	return ActionResult(extracted_content=text, include_in_memory=True)


@controller.action(
	'Upload cv to element - call this function to upload if element is not found, try with different index of the same upload element',
)
async def upload_cv(index: int, browser: BrowserContext):
	path = str(CV.absolute())
	dom_el = await browser.get_dom_element_by_index(index)

	if dom_el is None:
		return ActionResult(error=f'No element found at index {index}')

	file_upload_dom_el = dom_el.get_file_upload_element()

	if file_upload_dom_el is None:
		logger.info(f'No file upload element found at index {index}')
		return ActionResult(error=f'No file upload element found at index {index}')

	file_upload_el = await browser.get_locate_element(file_upload_dom_el)

	if file_upload_el is None:
		logger.info(f'No file upload element found at index {index}')
		return ActionResult(error=f'No file upload element found at index {index}')

	try:
		await file_upload_el.set_input_files(path)
		msg = f'Successfully uploaded file "{path}" to index {index}'
		logger.info(msg)
		return ActionResult(extracted_content=msg)
	except Exception as e:
		logger.debug(f'Error in set_input_files: {str(e)}')
		return ActionResult(error=f'Failed to upload file to index {index}')


browser = Browser(
	config=BrowserConfig(
		chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
		disable_security=True,
	)
)


async def main():
	# ground_task = (
	# 	'You are a professional job finder. '
	# 	'1. Read my cv with read_cv'
	# 	'2. Read the saved jobs file '
	# 	'3. start applying to the first link of Amazon '
	# 	'You can navigate through pages e.g. by scrolling '
	# 	'Make sure to be on the english version of the page'
	# )
	ground_task = (
		'You are a professional job finder. '
		'1. Read my cv with read_cv'
		'find ml internships in and save them to a file'
		'search at company:'
	)
	tasks = [
		ground_task + '\n' + 'Google',
		# ground_task + '\n' + 'Amazon',
		# ground_task + '\n' + 'Apple',
		# ground_task + '\n' + 'Microsoft',
		# ground_task
		# + '\n'
		# + 'go to https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/Taiwan%2C-Remote/Fulfillment-Analyst---New-College-Graduate-2025_JR1988949/apply/autofillWithResume?workerSubType=0c40f6bd1d8f10adf6dae42e46d44a17&workerSubType=ab40a98049581037a3ada55b087049b7 NVIDIA',
		# ground_task + '\n' + 'Meta',
	]
	model = AzureChatOpenAI(
		model='gpt-4o',
		api_version='2024-10-21',
		azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),
		api_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),
	)

	agents = []
	for task in tasks:
		agent = Agent(task=task, llm=model, controller=controller, browser=browser)
		agents.append(agent)

	await asyncio.gather(*[agent.run() for agent in agents])


if __name__ == "__main__":
	asyncio.run(main())


================================================
File: examples/use-cases/find_influencer_profiles.py
================================================
"""
Show how to use custom outputs.

@dev You need to add OPENAI_API_KEY to your environment variables.
"""

import json
import os
import sys
from typing import List

import requests

from browser_use.agent.views import ActionResult

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel

from browser_use import Agent, Controller

load_dotenv()


class Profile(BaseModel):
	platform: str
	profile_url: str


class Profiles(BaseModel):
	profiles: List[Profile]


controller = Controller(exclude_actions=['search_google'], output_model=Profiles)
BEARER_TOKEN = os.getenv('BEARER_TOKEN')

if not BEARER_TOKEN:
	# use the api key for ask tessa
	# you can also use other apis like exa, xAI, perplexity, etc.
	raise ValueError('BEARER_TOKEN is not set - go to https://www.heytessa.ai/ and create an api key')


@controller.registry.action('Search the web for a specific query')
async def search_web(query: str):
	keys_to_use = ['url', 'title', 'content', 'author', 'score']
	headers = {'Authorization': f'Bearer {BEARER_TOKEN}'}
	response = requests.post('https://asktessa.ai/api/search', headers=headers, json={'query': query})

	final_results = [
		{key: source[key] for key in keys_to_use if key in source}
		for source in response.json()['sources']
		if source['score'] >= 0.2
	]
	# print(json.dumps(final_results, indent=4))
	result_text = json.dumps(final_results, indent=4)
	print(result_text)
	return ActionResult(extracted_content=result_text, include_in_memory=True)


async def main():
	task = (
		'Go to this tiktok video url, open it and extract the @username from the resulting url. Then do a websearch for this username to find all his social media profiles. Return me the links to the social media profiles with the platform name.'
		' https://www.tiktokv.com/share/video/7470981717659110678/  '
	)
	model = ChatOpenAI(model='gpt-4o')
	agent = Agent(task=task, llm=model, controller=controller)

	history = await agent.run()

	result = history.final_result()
	if result:
		parsed: Profiles = Profiles.model_validate_json(result)

		for profile in parsed.profiles:
			print('\n--------------------------------')
			print(f'Platform:         {profile.platform}')
			print(f'Profile URL:      {profile.profile_url}')

	else:
		print('No result')


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/use-cases/google_sheets.py
================================================
import os
import sys

from browser_use.browser.context import BrowserContext

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
import asyncio

import pyperclip
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use import ActionResult, Agent, Controller
from browser_use.browser.browser import Browser, BrowserConfig

browser = Browser(
	config=BrowserConfig(
		chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
	),
)

# Load environment variables
load_dotenv()
if not os.getenv('OPENAI_API_KEY'):
	raise ValueError('OPENAI_API_KEY is not set. Please add it to your environment variables.')


controller = Controller()


def is_google_sheet(page) -> bool:
	return page.url.startswith('https://docs.google.com/spreadsheets/')


# TODO: refactor if not is_google_sheet(page): checks below to something like this:
# @controller.registry.action('Do something with a Google Sheet', page_filter=is_google_sheet)
# async def some_google_sheet_action(browser: BrowserContext):
# 	...


@controller.registry.action('Google Sheets: Open a specific Google Sheet')
async def open_google_sheet(browser: BrowserContext, google_sheet_url: str):
	page = await browser.get_current_page()
	if page.url != google_sheet_url:
		await page.goto(google_sheet_url)
		await page.wait_for_load_state()
	if not is_google_sheet(page):
		return ActionResult(error='Failed to open Google Sheet, are you sure you have permissions to access this sheet?')
	return ActionResult(extracted_content=f'Opened Google Sheet {google_sheet_url}', include_in_memory=False)


@controller.registry.action('Google Sheets: Get the contents of the entire sheet')
async def get_sheet_contents(browser: BrowserContext):
	page = await browser.get_current_page()
	if not is_google_sheet(page):
		return ActionResult(error='Current page is not a Google Sheet')

	# select all cells
	await page.keyboard.press('Enter')
	await page.keyboard.press('Escape')
	await page.keyboard.press('ControlOrMeta+A')
	await page.keyboard.press('ControlOrMeta+C')

	extracted_tsv = pyperclip.paste()
	return ActionResult(extracted_content=extracted_tsv, include_in_memory=True)


@controller.registry.action('Google Sheets: Select a specific cell or range of cells')
async def select_cell_or_range(browser: BrowserContext, cell_or_range: str):
	page = await browser.get_current_page()
	if not is_google_sheet(page):
		return ActionResult(error='Current page is not a Google Sheet')

	await page.keyboard.press('Enter')  # make sure we dont delete current cell contents if we were last editing
	await page.keyboard.press('Escape')  # to clear current focus (otherwise select range popup is additive)
	await asyncio.sleep(0.1)
	await page.keyboard.press('Home')  # move cursor to the top left of the sheet first
	await page.keyboard.press('ArrowUp')
	await asyncio.sleep(0.1)
	await page.keyboard.press('Control+G')  # open the goto range popup
	await asyncio.sleep(0.2)
	await page.keyboard.type(cell_or_range, delay=0.05)
	await asyncio.sleep(0.2)
	await page.keyboard.press('Enter')
	await asyncio.sleep(0.2)
	await page.keyboard.press('Escape')  # to make sure the popup still closes in the case where the jump failed
	return ActionResult(extracted_content=f'Selected cell {cell_or_range}', include_in_memory=False)


@controller.registry.action('Google Sheets: Get the contents of a specific cell or range of cells')
async def get_range_contents(browser: BrowserContext, cell_or_range: str):
	page = await browser.get_current_page()
	if not is_google_sheet(page):
		return ActionResult(error='Current page is not a Google Sheet')

	await select_cell_or_range(browser, cell_or_range)

	await page.keyboard.press('ControlOrMeta+C')
	await asyncio.sleep(0.1)
	extracted_tsv = pyperclip.paste()
	return ActionResult(extracted_content=extracted_tsv, include_in_memory=True)


@controller.registry.action('Google Sheets: Clear the currently selected cells')
async def clear_selected_range(browser: BrowserContext):
	page = await browser.get_current_page()
	if not is_google_sheet(page):
		return ActionResult(error='Current page is not a Google Sheet')

	await page.keyboard.press('Backspace')
	return ActionResult(extracted_content='Cleared selected range', include_in_memory=False)


@controller.registry.action('Google Sheets: Input text into the currently selected cell')
async def input_selected_cell_text(browser: BrowserContext, text: str):
	page = await browser.get_current_page()
	if not is_google_sheet(page):
		return ActionResult(error='Current page is not a Google Sheet')

	await page.keyboard.type(text, delay=0.1)
	await page.keyboard.press('Enter')  # make sure to commit the input so it doesnt get overwritten by the next action
	await page.keyboard.press('ArrowUp')
	return ActionResult(extracted_content=f'Inputted text {text}', include_in_memory=False)


@controller.registry.action('Google Sheets: Batch update a range of cells')
async def update_range_contents(browser: BrowserContext, range: str, new_contents_tsv: str):
	page = await browser.get_current_page()
	if not is_google_sheet(page):
		return ActionResult(error='Current page is not a Google Sheet')

	await select_cell_or_range(browser, range)

	# simulate paste event from clipboard with TSV content
	await page.evaluate(f"""
		const clipboardData = new DataTransfer();
		clipboardData.setData('text/plain', `{new_contents_tsv}`);
		document.activeElement.dispatchEvent(new ClipboardEvent('paste', {{clipboardData}}));
	""")

	return ActionResult(extracted_content=f'Updated cell {range} with {new_contents_tsv}', include_in_memory=False)


# many more snippets for keyboard-shortcut based Google Sheets automation can be found here, see:
# - https://github.com/philc/sheetkeys/blob/master/content_scripts/sheet_actions.js
# - https://github.com/philc/sheetkeys/blob/master/content_scripts/commands.js
# - https://support.google.com/docs/answer/181110?hl=en&co=GENIE.Platform%3DDesktop#zippy=%2Cmac-shortcuts

# Tip: LLM is bad at spacial reasoning, don't make it navigate with arrow keys relative to current cell
# if given arrow keys, it will try to jump from G1 to A2 by pressing Down, without realizing needs to go Down+LeftLeftLeftLeft


async def main():
	async with await browser.new_context() as context:
		model = ChatOpenAI(model='gpt-4o')

		eraser = Agent(
			task="""
				Clear all the existing values in columns A through F in this Google Sheet:
				https://docs.google.com/spreadsheets/d/1INaIcfpYXlMRWO__de61SHFCaqt1lfHlcvtXZPItlpI/edit
			""",
			llm=model,
			browser_context=context,
			controller=controller,
		)
		await eraser.run()

		researcher = Agent(
			task="""
				Google to find the full name, nationality, and date of birth of the CEO of the top 10 Fortune 100 companies.
				For each company, append a row to this existing Google Sheet: https://docs.google.com/spreadsheets/d/1INaIcfpYXlMRWO__de61SHFCaqt1lfHlcvtXZPItlpI/edit
				Make sure column headers are present and all existing values in the sheet are formatted correctly.
				Columns:
					A: Company Name
					B: CEO Full Name
					C: CEO Country of Birth
					D: CEO Date of Birth (YYYY-MM-DD)
					E: Source URL where the information was found
			""",
			llm=model,
			browser_context=context,
			controller=controller,
		)
		await researcher.run()

		improvised_continuer = Agent(
			task="""
				Read the Google Sheet https://docs.google.com/spreadsheets/d/1INaIcfpYXlMRWO__de61SHFCaqt1lfHlcvtXZPItlpI/edit
				Add 3 more rows to the bottom continuing the existing pattern, make sure any data you add is sourced correctly.
			""",
			llm=model,
			browser_context=context,
			controller=controller,
		)
		await improvised_continuer.run()

		final_fact_checker = Agent(
			task="""
				Read the Google Sheet https://docs.google.com/spreadsheets/d/1INaIcfpYXlMRWO__de61SHFCaqt1lfHlcvtXZPItlpI/edit
				Fact-check every entry, add a new column F with your findings for each row.
				Make sure to check the source URL for each row, and make sure the information is correct.
			""",
			llm=model,
			browser_context=context,
			controller=controller,
		)
		await final_fact_checker.run()


if __name__ == '__main__':
	asyncio.run(main())



================================================
File: examples/use-cases/online_coding_agent.py
================================================
# Goal: Implements a multi-agent system for online code editors, with separate agents for coding and execution.

import os
import sys
import asyncio

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langchain_openai import ChatOpenAI
from dotenv import load_dotenv

from browser_use import Agent, Browser

# Load environment variables
load_dotenv()
if not os.getenv('OPENAI_API_KEY'):
    raise ValueError('OPENAI_API_KEY is not set. Please add it to your environment variables.')

async def main():
    browser = Browser()
    async with await browser.new_context() as context:
        model = ChatOpenAI(model='gpt-4o')

        # Initialize browser agent
        agent1 = Agent(
            task='Open an online code editor programiz.',
            llm=model,
            browser_context=context,
        )
        executor = Agent(
            task='Executor. Execute the code written by the coder and suggest some updates if there are errors.',
            llm=model,
            browser_context=context,
        )

        coder = Agent(
            task='Coder. Your job is to write and complete code. You are an expert coder. Code a simple calculator. Write the code on the coding interface after agent1 has opened the link.',
            llm=model,
            browser_context=context,
        )
        await agent1.run()
        await executor.run()
        await coder.run()

if __name__ == "__main__":
    asyncio.run(main())


================================================
File: examples/use-cases/post-twitter.py
================================================
"""
Goal: Provides a template for automated posting on X (Twitter), including new tweets, tagging, and replies.

X Posting Template using browser-use
----------------------------------------

This template allows you to automate posting on X using browser-use.
It supports:
- Posting new tweets
- Tagging users
- Replying to tweets

Add your target user and message in the config section.

target_user="XXXXX"
message="XXXXX"
reply_url="XXXXX"

Any issues, contact me on X @defichemist95
"""

import os
import sys
from typing import Optional
import asyncio

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dataclasses import dataclass
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use.browser.browser import Browser, BrowserConfig
from browser_use import Agent, Controller

# Load environment variables
load_dotenv()
if not os.getenv('OPENAI_API_KEY'):
    raise ValueError('OPENAI_API_KEY is not set. Please add it to your environment variables.')

# ============ Configuration Section ============
@dataclass
class TwitterConfig:
    """Configuration for Twitter posting"""

    openai_api_key: str
    chrome_path: str
    target_user: str  # Twitter handle without @
    message: str
    reply_url: str
    headless: bool = False
    model: str = "gpt-4o-mini"
    base_url: str = "https://x.com/home"


# Customize these settings
config = TwitterConfig(
    openai_api_key=os.getenv("OPENAI_API_KEY"),
    chrome_path="/Applications/Google Chrome.app/Contents/MacOS/Google Chrome", # This is for MacOS (Chrome)
    target_user="XXXXX",
    message="XXXXX",
    reply_url="XXXXX",
    headless=False,
)


def create_twitter_agent(config: TwitterConfig) -> Agent:

    llm = ChatOpenAI(model=config.model, api_key=config.openai_api_key)

    browser = Browser(
        config=BrowserConfig(
            headless=config.headless,
            chrome_instance_path=config.chrome_path,
        )
    )

    controller = Controller()

    # Construct the full message with tag
    full_message = f"@{config.target_user} {config.message}"

    # Create the agent with detailed instructions
    return Agent(
        task=f"""Navigate to Twitter and create a post and reply to a tweet.

        Here are the specific steps:

        1. Go to {config.base_url}. See the text input field at the top of the page that says "What's happening?"
        2. Look for the text input field at the top of the page that says "What's happening?"
        3. Click the input field and type exactly this message:
        "{full_message}"
        4. Find and click the "Post" button (look for attributes: 'button' and 'data-testid="tweetButton"')
        5. Do not click on the '+' button which will add another tweet.

        6. Navigate to {config.reply_url}
        7. Before replying, understand the context of the tweet by scrolling down and reading the comments.
        8. Reply to the tweet under 50 characters.

        Important:
        - Wait for each element to load before interacting
        - Make sure the message is typed exactly as shown
        - Verify the post button is clickable before clicking
        - Do not click on the '+' button which will add another tweet
        """,
        llm=llm,
        controller=controller,
        browser=browser,
    )


async def post_tweet(agent: Agent):

    try:
        await agent.run(max_steps=100)
        agent.create_history_gif()
        print("Tweet posted successfully!")
    except Exception as e:
        print(f"Error posting tweet: {str(e)}")


async def main():
    agent = create_twitter_agent(config)
    await agent.run()

if __name__ == "__main__":
    asyncio.run(main())


================================================
File: examples/use-cases/scrolling_page.py
================================================
# Goal: Automates webpage scrolling with various scrolling actions and text search functionality.

import os
import sys
import asyncio

sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from langchain_openai import ChatOpenAI
from browser_use import Agent
from dotenv import load_dotenv

from browser_use.browser.browser import Browser, BrowserConfig

# Load environment variables
load_dotenv()
if not os.getenv('OPENAI_API_KEY'):
	raise ValueError('OPENAI_API_KEY is not set')

"""
Example: Using the 'Scroll down' action.

This script demonstrates how the agent can navigate to a webpage and scroll down the content.
If no amount is specified, the agent will scroll down by one page height.
"""

llm = ChatOpenAI(model='gpt-4o')

agent = Agent(
	# task="Navigate to 'https://en.wikipedia.org/wiki/Internet' and scroll down by one page - then scroll up by 100 pixels - then scroll down by 100 pixels - then scroll down by 10000 pixels.",
	task="Navigate to 'https://en.wikipedia.org/wiki/Internet' and scroll to the string 'The vast majority of computer'",
	llm=llm,
	browser=Browser(config=BrowserConfig(headless=False)),
)


async def main():
	await agent.run()


if __name__ == "__main__":
	asyncio.run(main())



================================================
File: examples/use-cases/shopping.py
================================================
from langchain_openai import ChatOpenAI
from browser_use import Agent, Browser, BrowserConfig
from dotenv import load_dotenv
load_dotenv()

import asyncio

task="""
   ### Prompt for Shopping Agent ‚Äì Migros Online Grocery Order

**Objective:**  
Visit [Migros Online](https://www.migros.ch/en), search for the required grocery items, add them to the cart, select an appropriate delivery window, and complete the checkout process using TWINT.

**Important:**
- Make sure that you don't buy more than it's needed for each article.
- After your search, if you click  the "+" button, it adds the item to the basket.
- if you open the basket sidewindow menu, you can close it by clicking the X button on the top right. This will help you navigate easier.
---

### Step 1: Navigate to the Website
- Open [Migros Online](https://www.migros.ch/en).
- You should be logged in as Nikolaos Kaliorakis

---

### Step 2: Add Items to the Basket

#### Shopping List:

**Meat & Dairy:**
- Beef Minced meat (1 kg)
- Gruy√®re cheese (grated preferably)
- 2 liters full-fat milk
- Butter (cheapest available)

**Vegetables:**
- Carrots (1kg pack)
- Celery
- Leeks (1 piece)
- 1 kg potatoes

At this stage, check the basket on the top right (indicates the price) and check if you bought the right items.

**Fruits:**
- 2 lemons
- Oranges (for snacking)

**Pantry Items:**
- Lasagna sheets
- Tahini
- Tomato paste (below CHF2)
- Black pepper refill (not with the mill)
- 2x 1L Oatly Barista(oat milk)
- 1 pack of eggs (10 egg package)

#### Ingredients I already have (DO NOT purchase):
- Olive oil, garlic, canned tomatoes, dried oregano, bay leaves, salt, chili flakes, flour, nutmeg, cumin.

---

### Step 3: Handling Unavailable Items
- If an item is **out of stock**, find the best alternative.
- Use the following recipe contexts to choose substitutions:
  - **Pasta Bolognese & Lasagna:** Minced meat, tomato paste, lasagna sheets, milk (for b√©chamel), Gruy√®re cheese.
  - **Hummus:** Tahini, chickpeas, lemon juice, olive oil.
  - **Chickpea Curry Soup:** Chickpeas, leeks, curry, lemons.
  - **Crispy Slow-Cooked Pork Belly with Vegetables:** Potatoes, butter.
- Example substitutions:
  - If Gruy√®re cheese is unavailable, select another semi-hard cheese.
  - If Tahini is unavailable, a sesame-based alternative may work.

---

### Step 4: Adjusting for Minimum Order Requirement
- If the total order **is below CHF 99**, add **a liquid soap refill** to reach the minimum. If it;s still you can buy some bread, dark chockolate.
- At this step, check if you have bought MORE items than needed. If the price is more then CHF200, you MUST remove items.
- If an item is not available, choose an alternative.
- if an age verification is needed, remove alchoholic products, we haven't verified yet.

---

### Step 5: Select Delivery Window
- Choose a **delivery window within the current week**. It's ok to pay up to CHF2 for the window selction.
- Preferably select a slot within the workweek.

---

### Step 6: Checkout
- Proceed to checkout.
- Select **TWINT** as the payment method.
- Check out.
- 
- if it's needed the userename is: nikoskalio.dev@gmail.com 
- and the password is : TheCircuit.Migros.dev!
---

### Step 7: Confirm Order & Output Summary
- Once the order is placed, output a summary including:
  - **Final list of items purchased** (including any substitutions).
  - **Total cost**.
  - **Chosen delivery time**.

**Important:** Ensure efficiency and accuracy throughout the process."""

browser = Browser()

agent = Agent(
   task=task,
    llm=ChatOpenAI(model="gpt-4o"),
    browser=browser,
    )

async def main():
    await agent.run()
    input("Press Enter to close the browser...")
    await browser.close()

if __name__ == '__main__':
    asyncio.run(main())



================================================
File: examples/use-cases/test_cv.txt
================================================
123



================================================
File: examples/use-cases/twitter_cookies.txt
================================================
[{
    "name": "auth_token",
    "value": "auth_token_cookie_value",
    "domain": ".x.com",
    "path": "/"
  },
{
    "name": "ct0",
    "value": "ct0_cookie_value",
    "domain": ".x.com",
    "path": "/"
}]



================================================
File: examples/use-cases/twitter_post_using_cookies.py
================================================
# Goal: Automates posting on X (Twitter) using stored authentication cookies. 

import asyncio
import os

from dotenv import load_dotenv
from langchain_google_genai import ChatGoogleGenerativeAI
from pydantic import SecretStr

from browser_use import Agent
from browser_use.browser.browser import Browser, BrowserConfig
from browser_use.browser.context import BrowserContext, BrowserContextConfig

load_dotenv()
api_key = os.getenv('GEMINI_API_KEY')
if not api_key:
	raise ValueError('GEMINI_API_KEY is not set')

llm = ChatGoogleGenerativeAI(model='gemini-2.0-flash-exp', api_key=SecretStr(api_key))


browser = Browser(
	config=BrowserConfig(
		# chrome_instance_path='/Applications/Google Chrome.app/Contents/MacOS/Google Chrome',
	)
)
file_path = os.path.join(os.path.dirname(__file__), 'twitter_cookies.txt')
context = BrowserContext(browser=browser, config=BrowserContextConfig(cookies_file=file_path))


async def main():
	agent = Agent(
		browser_context=context,
		task=('go to https://x.com. write a new post with the text "browser-use ftw", and submit it'),
		llm=llm,
		max_actions_per_step=4,
	)
	await agent.run(max_steps=25)
	input('Press Enter to close the browser...')


if __name__ == "__main__":
	asyncio.run(main())



================================================
File: examples/use-cases/web_voyager_agent.py
================================================
# Goal: A general-purpose web navigation agent for tasks like flight booking and course searching.

import os
import sys
import asyncio

# Adjust Python path
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from dotenv import load_dotenv
from pydantic import SecretStr
from langchain_openai import AzureChatOpenAI

from browser_use.agent.service import Agent
from browser_use.browser.browser import Browser, BrowserConfig, BrowserContextConfig

# Load environment variables
load_dotenv()

# Validate required environment variables
required_env_vars = ["AZURE_OPENAI_KEY", "AZURE_OPENAI_ENDPOINT"]
for var in required_env_vars:
    if not os.getenv(var):
        raise ValueError(f"{var} is not set. Please add it to your environment variables.")

browser = Browser(
	config=BrowserConfig(
		headless=False,  # This is True in production
		disable_security=True,
		new_context_config=BrowserContextConfig(
			disable_security=True,
			minimum_wait_page_load_time=1,  # 3 on prod
			maximum_wait_page_load_time=10,  # 20 on prod
			# no_viewport=True,
			browser_window_size={
				'width': 1280,
				'height': 1100,
			},
			# trace_path='./tmp/web_voyager_agent',
		),
	)
)
llm = AzureChatOpenAI(
	model='gpt-4o',
	api_version='2024-10-21',
	azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT', ''),
	api_key=SecretStr(os.getenv('AZURE_OPENAI_KEY', '')),
)

# TASK = """
# Find the lowest-priced one-way flight from Cairo to Montreal on February 21, 2025, including the total travel time and number of stops. on https://www.google.com/travel/flights/
# """
# TASK = """
# Browse Coursera, which universities offer Master of Advanced Study in Engineering degrees? Tell me what is the latest application deadline for this degree? on https://www.coursera.org/"""
TASK = """
Find and book a hotel in Paris with suitable accommodations for a family of four (two adults and two children) offering free cancellation for the dates of February 14-21, 2025. on https://www.booking.com/
"""


async def main():
	agent = Agent(
		task=TASK,
		llm=llm,
		browser=browser,
		validate_output=True,
	)
	history = await agent.run(max_steps=50)
	history.save_to_file('./tmp/history.json')


if __name__ == "__main__":
	asyncio.run(main())



================================================
File: examples/use-cases/wikipedia_banana_to_quantum.py
================================================
import asyncio

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI

from browser_use import Agent
from browser_use.browser.browser import Browser, BrowserConfig, BrowserContextConfig

load_dotenv()

# video https://preview.screen.studio/share/vuq91Ej8
llm = ChatOpenAI(
	model='gpt-4o',
	temperature=0.0,
)
task = 'go to https://en.wikipedia.org/wiki/Banana and click on buttons on the wikipedia page to go as fast as possible from banna to Quantum mechanics'

browser = Browser(
	config=BrowserConfig(
		new_context_config=BrowserContextConfig(
			viewport_expansion=-1,
			highlight_elements=False,
		),
	),
)
agent = Agent(task=task, llm=llm, browser=browser, use_vision=False)


async def main():
	await agent.run()


if __name__ == '__main__':
	asyncio.run(main())


